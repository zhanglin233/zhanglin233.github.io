{
    "version": "https://jsonfeed.org/version/1",
    "title": "欢迎来到我的个人博客 • All posts by \"面试\" tag",
    "description": "",
    "home_page_url": "http://zhanglin233.github.io",
    "items": [
        {
            "id": "http://zhanglin233.github.io/2021/12/26/computer-science/interview/%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95%E4%B9%8B%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/",
            "url": "http://zhanglin233.github.io/2021/12/26/computer-science/interview/%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%95%E4%B9%8B%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/",
            "title": "后端面试之操作系统",
            "date_published": "2021-12-26T05:59:55.365Z",
            "content_html": "<h1 id=\"操作系统基础\"><a class=\"anchor\" href=\"#操作系统基础\">#</a> 操作系统基础</h1>\n<h2 id=\"基本特征\"><a class=\"anchor\" href=\"#基本特征\">#</a> 基本特征</h2>\n<h3 id=\"并发和并行\"><a class=\"anchor\" href=\"#并发和并行\">#</a> 并发和并行</h3>\n<ul>\n<li>并发是指宏观上在一段时间内能同时运行多个程序，而并行是指在同一时刻可以同时运行多个指令</li>\n<li>操作系统通过引入进程和线程，使得程序能够并发运行</li>\n<li>并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统</li>\n</ul>\n<h3 id=\"共享\"><a class=\"anchor\" href=\"#共享\">#</a> 共享</h3>\n<ul>\n<li>共享是指系统中的资源可以被多个并发进程共同使用</li>\n<li>共享的方式有两种：<strong>互斥共享和同时共享</strong></li>\n<li>互斥共享的资源称为临界资源；例如打印机等，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问</li>\n</ul>\n<h3 id=\"虚拟\"><a class=\"anchor\" href=\"#虚拟\">#</a> 虚拟</h3>\n<ul>\n<li>虚拟技术把一个物理实体转换为多个逻辑实体</li>\n<li>虚拟技术主要有两种：时（时间）分复用技术和空（空间）分复用技术</li>\n<li>多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换</li>\n<li>虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行<strong>页面置换算法</strong>，将该页置换到内存中</li>\n</ul>\n<h3 id=\"异步\"><a class=\"anchor\" href=\"#异步\">#</a> 异步</h3>\n<ul>\n<li>异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进</li>\n</ul>\n<h2 id=\"基本功能\"><a class=\"anchor\" href=\"#基本功能\">#</a> 基本功能</h2>\n<ul>\n<li><strong>进程管理</strong>：进程控制、进程同步、进程通信、死锁处理、处理机调度等</li>\n<li><strong>内存管理</strong>：内存分配、地址映射、内存保护与共享、虚拟内存等</li>\n<li><strong>文件管理</strong>：文件存储空间的管理、目录管理、文件读写管理和保护等</li>\n<li><strong>设备管理</strong>：完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率，主要包括缓冲管理、设备分配、设备处理、虚拟设备等</li>\n</ul>\n<h2 id=\"系统调用\"><a class=\"anchor\" href=\"#系统调用\">#</a> 系统调用</h2>\n<p>如果一个进程在用户态需要使用内核态功能，就进行系统调用从而陷入内核态，之后由操作系统代为完成。</p>\n<ul>\n<li>工作流程为：\n<ul>\n<li>用户态程序将一些数据值放在寄存器中，或者使用参数创建一个栈帧 (stack frame), 以此表明需要操作系统提供的服务</li>\n<li>用户态程序执行陷阱指令（Trap Instruction，系统调用在 CPU 中的实现）</li>\n<li>CPU 切换到内核态，并跳到位于内存指定位置的指令，这些指令是操作系统的一部分，他们具有内存保护，不可被用户态程序访问</li>\n<li>这些指令称之为陷阱 (trap) 或者系统调用处理器 (system call handler). 他们会读取程序放入内存的数据参数，并执行程序请求的服务</li>\n<li>系统调用完成后，操作系统会重置 CPU 为用户态并返回系统调用的结果</li>\n</ul>\n</li>\n<li>Linux 的系统调用功能主要有：\n<ul>\n<li>进程控制： <code>fork();exit();wait()</code></li>\n<li>进程通信： <code>pipe();shmget();mmap()</code></li>\n<li>文件操作： <code>open();read();write()</code></li>\n<li>设备操作： <code>ioctl();read();write()</code></li>\n<li>信息维护： <code>getpid();alarm();sleep()</code></li>\n<li>安全： <code>chmod();umask();chown()</code></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"用户态和内核态\"><a class=\"anchor\" href=\"#用户态和内核态\">#</a> 用户态和内核态</h3>\n<ul>\n<li>内核态：CPU 可以访问内存的所有数据，包括外围设备，CPU 也可以将自己从一个程序切换到另一个程序</li>\n<li>用户态：只能受限的访问内存，且不允许访问外围设备，占用 CPU 的能力被剥夺，CPU 资源可以被其他程序获取</li>\n<li>切换的三种方式：系统调用（用户进程主动）、中断（被动）、外围设备中断（被动）\n<ul>\n<li>中断：当 CPU 在用户态下运行时发生一些没有预知的异常，这会触发由当前运行进程切换到处理此异常的内核相关进程中，也就是切换到内核态，比如缺页异常</li>\n<li>外围设备中断：当外围设备完成用户请求操作后，会向 CPU 发出相应的中断信号，这时 CPU 会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换</li>\n</ul>\n</li>\n<li>用户态切换到内核态的步骤：\n<ul>\n<li>从当前进程的描述符中提取其内核栈的 <code>ss0</code>  和 <code>esp0</code>  信息</li>\n<li>使用 <code>ss0</code>  和 <code>esp0</code>  指向的内核栈将当前进程的 <code>cs,eip,eflags,ss,esp</code>  信息保存起来，这个过程也完成了用户栈到内核栈的切换过程，同时保存了被暂停执行的程序的下一条指令</li>\n<li>将先前由中断向量检索得到的中断处理程序的 <code>cs,eip</code>  信息装入相应的寄存器，开始执行中断处理程序，这时就转到了内核态的程序执行了</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"中断分类\"><a class=\"anchor\" href=\"#中断分类\">#</a> 中断分类</h3>\n<ul>\n<li><strong>外中断</strong>：由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入 / 输出处理已经完成，处理器能够发送下一个输入 / 输出请求。此外还有时钟中断、控制台中断等</li>\n<li><strong>异常</strong>：由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等</li>\n<li><strong>陷入</strong>：用户程序使用系统调用</li>\n</ul>\n<h2 id=\"内核分类\"><a class=\"anchor\" href=\"#内核分类\">#</a> 内核分类</h2>\n<h3 id=\"大内核\"><a class=\"anchor\" href=\"#大内核\">#</a> 大内核</h3>\n<ul>\n<li>大内核是将操作系统功能作为一个紧密结合的整体放到内核</li>\n<li>由于各模块共享信息，因此有很高的性能</li>\n</ul>\n<h3 id=\"微内核\"><a class=\"anchor\" href=\"#微内核\">#</a> 微内核</h3>\n<ul>\n<li>由于操作系统不断复杂，因此将一部分操作系统功能移出内核，从而降低内核的复杂性。移出的部分根据分层的原则划分成若干服务，相互独立</li>\n<li>在微内核结构下，操作系统被划分成小的、定义良好的模块，只有微内核这一个模块运行在内核态，其余模块运行在用户态</li>\n<li>因为需要频繁地在用户态和核心态之间进行切换，所以会有一定的性能损失</li>\n</ul>\n<h2 id=\"软链接和硬链接区别\"><a class=\"anchor\" href=\"#软链接和硬链接区别\">#</a> 软链接和硬链接区别</h2>\n<ul>\n<li>建立软链接和硬链接的语法\n<ul>\n<li>软链接：ln -s 源文件 目标文件</li>\n<li>硬链接：ln 源文件 目标文件</li>\n</ul>\n</li>\n<li>软硬连接的理解\n<ul>\n<li>软连接类似于快捷方式，指向源文件的地址</li>\n<li>硬连接类似于 cp -p 加上同步更新</li>\n</ul>\n</li>\n<li>删除原文件对软硬链接的影响\n<ul>\n<li>软链接失效</li>\n<li>硬链接还可以查看</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"字节序大端小端\"><a class=\"anchor\" href=\"#字节序大端小端\">#</a> 字节序（大端小端）</h2>\n<ul>\n<li>大端字节序：高位字节在前，低位字节在后，这是人类读写数值的方法。</li>\n<li>小端字节序：低位字节在前，高位字节在后</li>\n</ul>\n<p>为什么要有大端小段？</p>\n<ul>\n<li>计算机电路先处理低位字节，效率比较高，因为计算都是从低位开始的。所以，计算机的内部处理都是小端字节序。</li>\n<li>但是，人类还是习惯读写大端字节序。所以，除了计算机的内部处理，其他的场合几乎都是大端字节序，比如网络传输和文件储存。</li>\n<li>一般只有读取外部数据的时候才需要考虑字节序</li>\n</ul>\n<p>常用系统的大小端</p>\n<ul>\n<li>\n<p>x86 字节序：小端</p>\n</li>\n<li>\n<p>macos：大端</p>\n</li>\n<li>\n<p>网络字节序大端：</p>\n<pre><code class=\"language-c++\">//将主机字节序转换为网络字节序\n unit32_t htonl (unit32_t hostlong);\n unit16_t htons (unit16_t hostshort);\n //将网络字节序转换为主机字节序\n unit32_t ntohl (unit32_t netlong);\n unit16_t ntohs (unit16_t netshort);\n123456\n</code></pre>\n</li>\n</ul>\n<p>如何判断</p>\n<ul>\n<li>** 判断的思路是：** 确定一个多字节的值（下面使用的是 4 字节的整数），将其写入内存（即赋值给一个变量），然后用指针取其首地址所对应的字节（即低地址的一个字节），判断该字节存放的是高位还是低位，高位说明是 Big endian，低位说明是 Little endian。</li>\n</ul>\n<h2 id=\"linux查看端口-进程常用命令\"><a class=\"anchor\" href=\"#linux查看端口-进程常用命令\">#</a> linux 查看端口、进程 (常用命令)</h2>\n<ul>\n<li>netstat -tunlp</li>\n<li>ps aux</li>\n<li>cat /proc/cpuinfo 显示 CPU info 的信息</li>\n<li>df -h 显示已经挂载的分区列表</li>\n<li>chmod ugo+rwx directory1 设置目录的所有人 (u)、群组 (g) 以及其他人 (o) 以读（r ）、</li>\n<li>tar -cvfj archive.tar.bz2 dir1 创建一个 bzip2 格式的压缩包<br />\n tar -jxvf archive.tar.bz2 解压一个 bzip2 格式的压缩包<br />\n tar -cvfz archive.tar.gz dir1 创建一个 gzip 格式的压缩包<br />\n tar -zxvf archive.tar.gz 解压一个 gzip 格式的压缩包</li>\n</ul>\n<h1 id=\"操作系统进程与线程\"><a class=\"anchor\" href=\"#操作系统进程与线程\">#</a> 操作系统进程与线程</h1>\n<h2 id=\"进程-线程和协程的概念\"><a class=\"anchor\" href=\"#进程-线程和协程的概念\">#</a> 进程、线程和协程的概念</h2>\n<ul>\n<li>进程是对运行时程序的封装，是系统进行资源调度和分配的的基本单位，实现了操作系统的并发。</li>\n<li>线程是进程内的一个执行实体或执行单元，是 CPU 调度和分派的基本单位，实现进程内部的并发。</li>\n<li>区别：\n<ul>\n<li>调度\n<ul>\n<li>一个线程只能属于一个进程，而一个进程至少有一个线程。</li>\n<li>进程不会相互影响，而线程挂掉一个就会导致整个进程挂掉</li>\n</ul>\n</li>\n<li>资源角度：\n<ul>\n<li>进程在执行过程中拥有独立的内存单元，而同一进程的多个线程共享进程的内存。每个线程都由自己独立的栈段。</li>\n<li>进程是资源分配的最小单位，线程是 CPU 调度的最小单位</li>\n</ul>\n</li>\n<li>系统开销\n<ul>\n<li>进程的创造销毁切换所花费的系统开销要与远大于线程的开销</li>\n</ul>\n</li>\n<li>进程间通信依靠 IPC，线程间通信直接读取共享数据段</li>\n<li>协程和线程区别\n<ul>\n<li>和多线程比，协程最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。</li>\n<li>第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"阻塞非阻塞同步异步\"><a class=\"anchor\" href=\"#阻塞非阻塞同步异步\">#</a> 阻塞，非阻塞，同步，异步</h2>\n<ul>\n<li>同步：在发出一个功能调用的时候，在没有得到结果之前，该调用就不返回。（该调用还处于激活状态）</li>\n<li>异步：当一个异步调用发出后，调用这并不能立刻得到结果。实际处理调用的部件在完成后通过状态、通知和回调来通知调用者。</li>\n<li>阻塞：阻塞调用在调用结果返回之前，线程会被挂起。只有在得到结果之后才会返回。</li>\n<li>非阻塞：调用再不能立刻得到结果之前，函数不会阻塞当前进程，而会立刻返回。（recv 接收数据）</li>\n</ul>\n<h2 id=\"进程状态转换图\"><a class=\"anchor\" href=\"#进程状态转换图\">#</a> 进程状态转换图</h2>\n<p><img data-src=\"https://img-blog.csdnimg.cn/img_convert/522239cb3769cbcb3953658c24d3831f.png\" alt=\"img\" /></p>\n<p>1）创建状态：进程正在被创建</p>\n<p>2）就绪状态：进程被加入到就绪队列中等待 CPU 调度运行</p>\n<p>3）执行状态：进程正在被运行</p>\n<p>4）等待阻塞状态：进程因为某种原因，比如等待 I/O，等待设备，而暂时不能运行。</p>\n<p>5）终止状态：进程运行完毕</p>\n<ul>\n<li>\n<p>交换技术</p>\n<p>当多个进程竞争内存资源时，会造成内存资源紧张，并且，如果此时没有就绪进程，处理机会空闲，I/0 速度比处理机速度慢得多，可能出现全部进程阻塞等待 I/O。</p>\n<p>针对以上问题，提出了两种解决方法：</p>\n<ul>\n<li>1）交换技术：换出一部分进程到外存，腾出内存空间。</li>\n<li>2）虚拟存储技术：每个进程只能装入一部分程序和数据。</li>\n</ul>\n<p>在交换技术上，将内存暂时不能运行的进程，或者暂时不用的数据和程序，换出到外存，来腾出足够的内存空间，把已经具备运行条件的进程，或进程所需的数据和程序换入到内存。从而出现了进程的挂起状态：进程被交换到外存，进程状态就成为了挂起状态。</p>\n</li>\n<li>\n<p>活动阻塞，静止阻塞，活动就绪，静止就绪</p>\n<ul>\n<li>1）活动阻塞：进程在内存，但是由于某种原因被阻塞了。</li>\n<li>2）静止阻塞：进程在外存，同时被某种原因阻塞了。</li>\n<li>3）活动就绪：进程在内存，处于就绪状态，只要给 CPU 和调度就可以直接运行。</li>\n<li>4）静止就绪：进程在外存，处于就绪状态，只要调度到内存，给 CPU 和调度就可以运行。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"哪些情况进程会由运行转化为阻塞\"><a class=\"anchor\" href=\"#哪些情况进程会由运行转化为阻塞\">#</a> 哪些情况进程会由运行转化为阻塞</h3>\n<ul>\n<li>进程缺少相应 io 资源</li>\n<li>访问正在被其他进程访问的临界资源，等待解锁</li>\n<li>进程睡眠</li>\n</ul>\n<h2 id=\"进程之间的通信方式以及优缺点\"><a class=\"anchor\" href=\"#进程之间的通信方式以及优缺点\">#</a> 进程之间的通信方式以及优缺点</h2>\n<ul>\n<li>\n<p>管道（PIPE）</p>\n<ul>\n<li>有名管道：一种半双工的通信方式，它允许无亲缘关系进程间的通信\n<ul>\n<li>优点：可以实现任意关系的进程间的通信</li>\n<li>缺点：\n<ol>\n<li>长期存于系统中，使用不当容易出错</li>\n<li>缓冲区有限</li>\n</ol>\n</li>\n<li>使用：\n<ol>\n<li><strong>int</strong> <strong>mkfifo</strong>(<strong>const</strong> <strong>char</strong> *path, <strong>mode_t</strong> mode);</li>\n<li><strong>int</strong> <strong>mkfifoat</strong>(<strong>int</strong> fd, <strong>const</strong> <strong>char</strong> *path, <strong>mode_t</strong> mode);</li>\n</ol>\n</li>\n</ul>\n</li>\n<li>无名管道：一种半双工的通信方式，只能在具有亲缘关系的进程间使用（父子进程）\n<ul>\n<li>优点：简单方便</li>\n<li>缺点：\n<ol>\n<li>局限于单向通信</li>\n<li>只能创建在它的进程以及其有亲缘关系的进程之间</li>\n<li>缓冲区有限</li>\n</ol>\n</li>\n<li>使用：\n<ol>\n<li>父进程创建一个管道，创建一个数组作为索引。（int pipe（int fd [2]））</li>\n<li>fork 一个子进程，子进程会复制父进程的管道文件。父子进程根据需要各自关闭读写端。</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>信号量（Semaphore）：一个计数器，可以用来控制多个线程对共享资源的访问</p>\n<ul>\n<li>优点：可以同步进程</li>\n<li>缺点：信号量有限</li>\n<li>使用（SIGHUP）子进程监视父进程是否存在，接收父进程死亡的信号</li>\n<li>只有当管道所有的读端都被关闭时，才会产生 SIGPIPE</li>\n</ul>\n</li>\n<li>\n<p>信号（Signal）：一种比较复杂的通信方式，用于通知接收进程某个事件已经发生</p>\n</li>\n<li>\n<p>消息队列（Message Queue）：是消息的链表，存放在内核中并由消息队列标识符标识</p>\n<ul>\n<li>优点：可以实现任意进程间的通信，并通过系统调用函数来实现消息发送和接收之间的同步，无需考虑同步问题，方便</li>\n<li>缺点：信息的复制需要额外消耗 CPU 的时间，不适宜于信息量大或操作频繁的场合</li>\n</ul>\n</li>\n<li>\n<p>共享内存（Shared Memory）：共享内存就是允许两个或多个进程共享一定的存储区。就如同 malloc () 函数向不同进程返回了指向同一个物理内存区域的指针。当一个进程改变了这块地址中的内容的时候，其它进程都会察觉到这个更改。因为数据不需要在客户机和服务器端之间复制，数据直接写到内存，不用若干次数据拷贝，所以这是最快的一种 IPC。</p>\n<p>注：共享内存没有任何的同步与互斥机制，所以要使用信号量来实现对共享内存的存取的同步。</p>\n<ul>\n<li>\n<p>优点：无须复制，快捷，信息量大</p>\n</li>\n<li>\n<p>缺点：</p>\n<ol>\n<li>通信是通过将共享空间缓冲区直接附加到进程的虚拟地址空间中来实现的，因此进程间的读写操作的同步问题</li>\n<li>利用内存缓冲区直接交换信息，内存的实体存在于计算机中，只能同一个计算机系统中的诸多进程共享，不方便网络通信</li>\n</ol>\n</li>\n<li>\n<pre><code>int` `shmget(key_t key, ``size_t` `size, ``int` `shmflg);\n1\n</code></pre>\n<p>(1) 第一个参数 key 是长整型（唯一非零），系统建立 IPC 通讯 （ 消息队列、 信号量和 共享内存） 时必须指定一个 ID 值。通常情况下，该 id 值通过 ftok 函数得到，由内核变成标识符，要想让两个进程看到同一个信号集，只需设置 key 值不变就可以。</p>\n<p>(2) 第二个参数 size 指定共享内存的大小，它的值一般为一页大小的整数倍（未到一页，操作系统向上对齐到一页，但是用户实际能使用只有自己所申请的大小）。</p>\n<p>(3) 第三个参数 shmflg 是一组标志，创建一个新的共享内存，将 shmflg 设置了 IPC_CREAT 标志后，共享内存存在就打开。而 IPC_CREAT | IPC_EXCL 则可以创建一个新的，唯一的共享内存，如果共享内存已存在，返回一个错误。一般我们会还或上一个文件权限</p>\n</li>\n</ul>\n</li>\n<li>\n<p>套接字（Socket）：可用于不同计算机间的进程通信</p>\n<ul>\n<li>优点：\n<ol>\n<li>传输数据为字节级，传输数据可自定义，数据量小效率高</li>\n<li>传输数据时间短，性能高</li>\n<li>适合于客户端和服务器端之间信息实时交互</li>\n<li>可以加密，数据安全性强</li>\n</ol>\n</li>\n<li>缺点：需对传输的数据进行解析，转化成应用级的数据。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"进程间的调度算法\"><a class=\"anchor\" href=\"#进程间的调度算法\">#</a> 进程间的调度算法</h2>\n<ul>\n<li>批处理系统：先来先服务、短作业优先、最短剩余时间优先</li>\n<li>交互式系统：时间片轮转、优先级调度，多级反馈队列</li>\n</ul>\n<h2 id=\"线程之间的通信方式\"><a class=\"anchor\" href=\"#线程之间的通信方式\">#</a> 线程之间的通信方式</h2>\n<ul>\n<li>锁机制：包括互斥锁 / 量（mutex）、读写锁（reader-writer lock）、自旋锁（spin lock）、条件变量（condition）\n<ul>\n<li>互斥锁 / 量（mutex）：提供了以排他方式防止数据结构被并发修改的方法。</li>\n<li>读写锁（reader-writer lock）：允许多个线程同时读共享数据，而对写操作是互斥的。（shared_mutex）\n<ul>\n<li>shared_mutex 比一般的 mutex 多了函数 lock_shared ()/unlock_shared (), 允许多个（读者）线程同时加锁、解锁，而 shared_lock 则相当于共享版的 lock_guard。</li>\n<li>对 shared_mutex 使用 lock_guard 或者 unique_lock 即达到了写着独占的目的。</li>\n</ul>\n</li>\n<li>自旋锁（spin lock）与互斥锁类似，都是为了保护共享资源。互斥锁是当资源被占用，申请者进入睡眠状态；而自旋锁则循环检测保持者是否已经释放锁。\n<ul>\n<li>自旋锁主要适用于被持有时间短，线程不希望在重新调度上花过多时间的情况。实际上许多其他类型的锁在底层使用了自旋锁实现，例如多数互斥锁在试图获取锁的时候会先自旋一小段时间，然后才会休眠。如果在持锁时间很长的场景下使用自旋锁，则会导致 CPU 在这个线程的时间片用尽之前一直消耗在无意义的忙等上，造成计算资源的浪费。</li>\n</ul>\n</li>\n<li>条件变量（condition）：可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。\n<ul>\n<li>condition</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>信号量机制 (Semaphore)\n<ul>\n<li>无名线程信号量</li>\n<li>命名线程信号量</li>\n</ul>\n</li>\n<li>信号机制 (Signal)：类似进程间的信号处理</li>\n<li>屏障（barrier）：屏障允许每个线程等待，直到所有的合作线程都达到某一点，然后从该点继续执行。</li>\n</ul>\n<p>线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制</p>\n<h2 id=\"进程-线程之间私有和共享的资源\"><a class=\"anchor\" href=\"#进程-线程之间私有和共享的资源\">#</a> 进程、线程之间私有和共享的资源</h2>\n<h3 id=\"进程之间私有和共享的资源\"><a class=\"anchor\" href=\"#进程之间私有和共享的资源\">#</a> 进程之间私有和共享的资源</h3>\n<ul>\n<li>私有：地址空间、堆、全局变量、栈、寄存器</li>\n<li>共享：代码段，公共数据，进程目录，进程 ID</li>\n</ul>\n<h3 id=\"线程之间私有和共享的资源\"><a class=\"anchor\" href=\"#线程之间私有和共享的资源\">#</a> 线程之间私有和共享的资源</h3>\n<ul>\n<li>私有：线程栈，寄存器，程序计数器</li>\n<li>共享：堆，地址空间，全局变量，静态变量</li>\n</ul>\n<h2 id=\"多进程和多线程对比\"><a class=\"anchor\" href=\"#多进程和多线程对比\">#</a> 多进程和多线程对比</h2>\n<table>\n<thead>\n<tr>\n<th>对比维度</th>\n<th>多进程</th>\n<th>多线程</th>\n<th>总结</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>数据共享、同步</td>\n<td>数据共享复杂，需要用 IPC；数据是分开的，同步简单</td>\n<td>因为共享进程数据，数据共享简单，但也是因为这个原因导致同步复杂</td>\n<td>各有优势</td>\n</tr>\n<tr>\n<td>内存、CPU</td>\n<td>占用内存多，切换复杂，CPU 利用率低</td>\n<td>占用内存少，切换简单，CPU 利用率高</td>\n<td>线程占优</td>\n</tr>\n<tr>\n<td>创建销毁、切换</td>\n<td>创建销毁、切换复杂，速度慢</td>\n<td>创建销毁、切换简单，速度很快</td>\n<td>线程占优</td>\n</tr>\n<tr>\n<td>编程、调试</td>\n<td>编程简单，调试简单</td>\n<td>编程复杂，调试复杂</td>\n<td>进程占优</td>\n</tr>\n<tr>\n<td>可靠性</td>\n<td>进程间不会互相影响</td>\n<td>一个线程挂掉将导致整个进程挂掉</td>\n<td>进程占优</td>\n</tr>\n<tr>\n<td>分布式</td>\n<td>适应于多核、多机分布式；如果一台机器不够，扩展到多台机器比较简单</td>\n<td>适应于多核分布式</td>\n<td>进程占优</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"多进程和多线程优劣\"><a class=\"anchor\" href=\"#多进程和多线程优劣\">#</a> 多进程和多线程优劣</h3>\n<table>\n<thead>\n<tr>\n<th>优劣</th>\n<th>多进程</th>\n<th>多线程</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>优点</td>\n<td>编程、调试简单，可靠性较高</td>\n<td>创建、销毁、切换速度快，内存、资源占用小</td>\n</tr>\n<tr>\n<td>缺点</td>\n<td>创建、销毁、切换速度慢，内存、资源占用大</td>\n<td>编程、调试复杂，可靠性较差</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"多进程和多线程选择\"><a class=\"anchor\" href=\"#多进程和多线程选择\">#</a> 多进程和多线程选择</h3>\n<ul>\n<li>需要频繁创建销毁的优先用线程</li>\n<li>需要进行大量计算的优先使用线程</li>\n<li>强相关的处理用线程，弱相关的处理用进程</li>\n<li>可能要扩展到多机分布的用进程，多核分布的用线程</li>\n<li>都满足需求的情况下，用你最熟悉、最拿手的方式</li>\n</ul>\n<h2 id=\"fork函数pid_t-fork-void\"><a class=\"anchor\" href=\"#fork函数pid_t-fork-void\">#</a> fork 函数（pid_t fork (void);）</h2>\n<ul>\n<li>\n<p>调用后执行的功能</p>\n<ul>\n<li>向系统申请一个新 PID</li>\n<li>创建子进程，复制父进程的 PCB，获得父进程的数据空间、堆、栈等资源的副本</li>\n<li>在父进程中返回子进程的 PID，在子进程中返回 0</li>\n<li>执行完以上动作后，父进程和子进程便开始并发执行了。</li>\n<li>fork () 返回值</li>\n<li>父进程中的 fork () 结束后返回子进程的 pid</li>\n<li>子进程中的 fork () 结束后返回 0</li>\n<li>错误返回负值</li>\n</ul>\n</li>\n<li>\n<p>写时拷贝</p>\n<ul>\n<li>如果每一次 fork () 都要拷贝很浪费内存，linux 中就在 fork () 后让父子进程共享内存，当进行写操作时再进行拷贝</li>\n</ul>\n</li>\n<li>\n<p>fork 和 vfork 的区别：</p>\n<p>\\1. fork () 的子进程拷贝父进程的数据段和代码段；vfork () 的子进程与父进程共享数据段</p>\n<p>\\2. fork () 的父子进程的执行次序不确定；vfork () 保证子进程先运行，在调用 exec 或 exit 之前与父进程数据是共享的，在它调用 exec 或 exit 之后父进程才可能被调度运行。</p>\n<p>\\3. vfork ( ) 保证子进程先运行，在它调用 exec 或 exit 之后父进程才可能被调度运行。如果在调用这两个函数之前子进程依赖于父进程的进一步动作，则会导致死锁。</p>\n<p>4. 当需要改变共享数据段中变量的值，则拷贝父进程。</p>\n</li>\n<li>\n<p>fork 实例</p>\n</li>\n</ul>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">void</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>\t<span class=\"token class-name\">pid_t</span> pid<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>\t<span class=\"token function\">signal</span><span class=\"token punctuation\">(</span>SIGCHLD<span class=\"token punctuation\">,</span> SIG_IGN<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>\t<span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"before fork pid:%d\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token function\">getpid</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>\t<span class=\"token keyword\">int</span> abc <span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>\tpid <span class=\"token operator\">=</span> <span class=\"token function\">fork</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>pid<span class=\"token operator\">==</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>        <span class=\"token function\">perror</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"tile\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>\t\t<span class=\"token keyword\">return</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>pid<span class=\"token operator\">==</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>        abc<span class=\"token operator\">++</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>\t\t<span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"child:%d,parent: %d\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token function\">getpid</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token function\">getppid</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>\t\t<span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"abc:%d\"</span><span class=\"token punctuation\">,</span> abc<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>\t<span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>    <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>pid<span class=\"token operator\">></span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>        abc<span class=\"token operator\">++</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>\t\t<span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"parent:pid:%d \\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token function\">getpid</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>\t\t<span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"abc:%d \\n\"</span><span class=\"token punctuation\">,</span> abc<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>\t\t<span class=\"token function\">sleep</span><span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>    <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"fork after...\\n\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre><span class=\"token number\">123456789101112131415161718192021222324</span></pre></td></tr></table></figure><h3 id=\"\"><a class=\"anchor\" href=\"#\">#</a> </h3>\n<h2 id=\"线程池原理\"><a class=\"anchor\" href=\"#线程池原理\">#</a> 线程池原理</h2>\n<ul>\n<li>多线程技术主要解决处理器单元内多个线程执行的问题，它可以显著减少处理器单元的闲置时间，增加处理器单元的吞吐能力，假设一个服务器完成一项任务所需时间为：T1 创建线程时间，T2 在线程中执行任务的时间，T3 销毁线程时间。</li>\n<li>如果：T1 + T3 远大于 T2，则可以采用线程池，以提高服务器性能。</li>\n<li>一个线程池包括以下四个基本组成部分：<br />\n1、线程池管理器（ThreadPool）：用于创建并管理线程池，包括 创建线程池，销毁线程池，添加新任务；<br />\n2、工作线程（PoolWorker）：线程池中线程，在没有任务时处于等待状态，可以循环的执行任务；<br />\n3、任务接口（Task）：每个任务必须实现的接口，以供工作线程调度任务的执行，它主要规定了任务的入口，任务执行完后的收尾工作，任务的执行状态等；<br />\n4、任务队列（taskQueue）：用于存放没有处理的任务。提供一种缓冲机制。</li>\n<li>线程池技术正是关注如何缩短或调整 T1,T3 时间的技术，从而提高服务器程序性能的。它把 T1，T3 分别安排在服务器程序的启动和结束的时间段或者一些空闲的时间段，这样在服务器程序处理客户请求时，不会有 T1，T3 的开销了。<br />\n线程池不仅调整 T1,T3 产生的时间段，而且它还显著减少了创建线程的数目，看一个例子：<br />\n假设一个服务器一天要处理 50000 个请求，并且每个请求需要一个单独的线程完成。在线程池中，线程数一般是固定的，所以产生线程总数不会超过线程池中线程的数目，而如果服务器不利用线程池来处理这些请求则线程总数为 50000。一般线程池大小是远小于 50000。所以利用线程池的服务器程序不会为了创建 50000 而在处理请求时浪费时间，从而提高效率。</li>\n<li>怎么实现线程池\n<ul>\n<li>1. 设置一个生产者消费者队列，作为临界资源</li>\n<li>2. 初始化 n 个线程，并让其运行起来，加锁去队列取任务运行</li>\n<li>3. 当任务队列为空的时候，所有线程阻塞</li>\n<li>4. 当生产者队列来了一个任务后，先对队列加锁，把任务挂在到队列上，然后使用条件变量去通知阻塞中的一个线程</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"正常进程-僵尸进程和孤儿进程\"><a class=\"anchor\" href=\"#正常进程-僵尸进程和孤儿进程\">#</a> 正常进程、僵尸进程和孤儿进程</h3>\n<ul>\n<li>\n<p>正常进程</p>\n<ul>\n<li>\n<p>正常情况下，子进程是通过父进程创建的，子进程再创建新的进程。子进程的结束和父进程的运行是一个异步过程，即父进程永远无法预测子进程到底什么时候结束。 当一个进程完成它的工作终止之后，它的父进程需要调用 wait () 或者 waitpid () 系统调用取得子进程的终止状态。</p>\n<p>unix 提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息， 就可以得到：在每个进程退出的时候，内核释放该进程所有的资源，包括打开的文件，占用的内存等。 但是仍然为其保留一定的信息，直到父进程通过 wait /waitpid 来取时才释放。保存信息包括：</p>\n<p>1 进程号 the process ID</p>\n<p>2 退出状态 the termination status of the process</p>\n<p>3 运行时间 the amount of CPU time taken by the process 等</p>\n</li>\n</ul>\n</li>\n<li>\n<p>孤儿进程</p>\n<ul>\n<li>一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被 init 进程 (进程号为 1) 所收养，并由 init 进程对它们完成状态收集工作。</li>\n</ul>\n</li>\n<li>\n<p>僵尸进程</p>\n<ul>\n<li>\n<p>一个进程使用 fork 创建子进程，如果子进程退出，而父进程并没有调用 wait 或 waitpid 获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵尸进程。</p>\n<p>僵尸进程是一个进程必然会经过的过程：这是每个子进程在结束时都要经过的阶段。</p>\n<p>如果子进程在 exit () 之后，父进程没有来得及处理，这时用 ps 命令就能看到子进程的状态是 “Z”。如果父进程能及时 处理，可能用 ps 命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。</p>\n<p>如果父进程在子进程结束之前退出，则子进程将由 init 接管。init 将会以父进程的身份对僵尸状态的子进程进行处理。</p>\n</li>\n</ul>\n</li>\n<li>\n<p>危害：</p>\n<ul>\n<li>如果进程不调用 wait /waitpid 的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程。</li>\n</ul>\n</li>\n<li>\n<p>外部消灭：</p>\n<ul>\n<li>通过 kill 发送 SIGTERM 或者 SIGKILL 信号消灭产生僵尸进程的进程，它产生的僵死进程就变成了孤儿进程，这些孤儿进程会被 init 进程接管，init 进程会 wait () 这些孤儿进程，释放它们占用的系统进程表中的资源</li>\n</ul>\n</li>\n<li>\n<p>内部解决：</p>\n<ul>\n<li>1、子进程退出时向父进程发送 SIGCHILD 信号，父进程处理 SIGCHILD 信号。在信号处理函数中调用 wait 进行处理僵尸进程。</li>\n<li>2、fork 两次，原理是将子进程成为孤儿进程，从而其的父进程变为 init 进程，通过 init 进程可以处理僵尸进程。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"死锁\"><a class=\"anchor\" href=\"#死锁\">#</a> 死锁</h2>\n<h3 id=\"原因\"><a class=\"anchor\" href=\"#原因\">#</a> 原因</h3>\n<ul>\n<li>系统资源不足</li>\n<li>资源分配不当</li>\n<li>进程运行推进顺序不合适</li>\n</ul>\n<h3 id=\"产生条件\"><a class=\"anchor\" href=\"#产生条件\">#</a> 产生条件</h3>\n<ul>\n<li>互斥</li>\n<li>请求和保持</li>\n<li>不剥夺</li>\n<li>环路</li>\n</ul>\n<h3 id=\"编码时解决死锁\"><a class=\"anchor\" href=\"#编码时解决死锁\">#</a> 编码时解决死锁</h3>\n<ul>\n<li>\n<p>死锁的一般解决方案：</p>\n<ul>\n<li>只要保证两个互斥量上锁的顺序一致，就不会死锁</li>\n<li>std::lock () 函数模板\n<ul>\n<li>能力：一次锁住两个或者两个以上的互斥量（至少两个，多个不行，1 个不行）；</li>\n<li>不存在因为锁头的顺序问题导致的死锁风险问题</li>\n<li>原理，std::lock ()：要么两个互斥量都缩住，要么两个互斥量都没锁柱，一旦有一个没锁住就会解锁另一个已经锁住的互斥量。</li>\n</ul>\n</li>\n</ul>\n<pre><code class=\"language-c++\">\t\tstd::lock(my_mutex1, my_mutex2);\n// \t\tmy_mutex2.lock();\n// \t\tmy_mutex1.lock();\n123\n</code></pre>\n</li>\n<li>\n<p>std::lock_guard 的 std::adopt_lock 参数</p>\n<ul>\n<li>adopt_lock 是一个结构体对象，起标记作用，标记已经此锁已经 lock</li>\n</ul>\n<pre><code class=\"language-c++\">std::lock(my_mutex1, my_mutex2);\nstd::lock_guard&lt;std::mutex&gt;sbgurad1(my_mutex1,std::adopt_lock); //用一个大括号包含需要加锁的代码段，提前结束lock_guard的生命周期\nstd::lock_guard&lt;std::mutex&gt;sbgurad2(my_mutex2,std::adopt_lock); \n123\n</code></pre>\n</li>\n</ul>\n<h3 id=\"处理方法\"><a class=\"anchor\" href=\"#处理方法\">#</a> 处理方法</h3>\n<ul>\n<li>\n<p><strong>鸵鸟策略</strong>：当作没有发生死锁</p>\n<ul>\n<li>因为解决死锁的代价很大，因此这种方案可以获得更高的性能；当发生死锁时不会对用户造成很大影响，或者发生死锁的概率很低，可以采用鸵鸟策略；大多数操作系统，包括 <code>unix</code> ， <code>linux</code>  和 <code>windows</code>  处理死锁问题的办法仅仅是忽略他</li>\n</ul>\n</li>\n<li>\n<p><strong>死锁检测和死锁恢复</strong>：不试图阻止死锁，而是检测到死锁发生时，采取措施进行恢复</p>\n<ul>\n<li>每种类型一个资源的死锁检测通过检测有向图是否存在环来实现。</li>\n<li>每种类型多个资源的死锁检测</li>\n<li>死锁恢复：利用抢占恢复，利用回滚恢复，通过杀死进程恢复</li>\n</ul>\n</li>\n<li>\n<p><strong>死锁预防</strong>：在程序运行之前预防死锁</p>\n<ul>\n<li>破坏互斥条件</li>\n<li>破坏占有和等待条件：一种方式是规定所有进程在开始执行前请求所需的全部资源</li>\n<li>破坏不可抢占条件</li>\n<li>破坏环路等待：给资源统一编号，进程只能按照编号顺序来请求资源</li>\n</ul>\n</li>\n<li>\n<p><strong>死锁避免</strong>：在运行时避免发生死锁</p>\n<ul>\n<li>\n<p><strong>安全状态</strong>：是指如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每个进程运行完毕，则称该状态是安全的</p>\n<p><img data-src=\"https://blog.csdn.net/weixin_42699130/article//assets/post/2020-02-15/safestate.png\" alt=\"img\" /></p>\n</li>\n<li>\n<p>上图中，图 a 的第二列 Has 表示进程已经拥有的资源数，第三列 Max 表示进程总共需要的资源数，Free 表示还有可以使用的资源数。从图 a 开始，先让 B 拥有所需的有时又资源，运行结束后释放 B，此时 free 变为 5；以同样方式运行 C 和 A，使得所有进程都能成功运行，因此可以<strong>称 A 的状态是安全</strong>的。</p>\n</li>\n<li>\n<p><strong>银行家算法</strong>：判断对请求的满足是否会进入不安全状态，如果是就拒绝请求；否则予以分配</p>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"linux的4种锁机制\"><a class=\"anchor\" href=\"#linux的4种锁机制\">#</a> Linux 的 4 种锁机制：</h2>\n<ul>\n<li>互斥锁：互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会进入睡眠，等待锁释放时被唤醒</li>\n<li>读写锁：rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。 注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于写数据的频率的场合。</li>\n<li>自旋锁：spinlock，在任何时刻同样只能有一个线程访问对象。但是当获取锁操作失败时，不会进入睡眠，而是会在原地自旋，直到锁被释放。这样节省了线程从睡眠状态到被唤醒期间的消耗，在加锁时间短暂的环境下会极大的提高效率。但如果加锁时间过长，则会非常浪费 CPU 资源。</li>\n<li>RCU：即 read-copy-update，在修改数据时，首先需要读取数据，然后生成一个副本，对副本进行修改。修改完成后，再将老数据 update 成新的数据。使用 RCU 时，读者几乎不需要同步开销，既不需要获得锁，也不使用原子指令，不会导致锁竞争，因此就不用考虑死锁问题了。而对于写者的同步开销较大，它需要复制被修改的数据，还必须使用锁机制同步并行其它写者的修改操作。在有大量读操作，少量写操作的情况下效率非常高。</li>\n</ul>\n<h2 id=\"经典同步问题\"><a class=\"anchor\" href=\"#经典同步问题\">#</a> 经典同步问题</h2>\n<h3 id=\"哲学家进餐问题\"><a class=\"anchor\" href=\"#哲学家进餐问题\">#</a> 哲学家进餐问题</h3>\n<p>多个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。</p>\n<p>下面是一种错误的解法，如果所有哲学家同时拿起左手边的筷子，那么所有哲学家都在等待其它哲学家吃完并释放自己手中的筷子，导致死锁。</p>\n<pre><code class=\"language-c++\">#define N 5\nvoid philosopher(int i) &#123;\n    while(TRUE) &#123;\n        think();\n        take(i);       // 拿起左边的筷子\n        take((i+1)%N); // 拿起右边的筷子\n        eat();\n        put(i);\n        put((i+1)%N);\n    &#125;\n&#125;\n1234567891011\n</code></pre>\n<p>为了防止死锁的发生，可以设置两个条件：</p>\n<ul>\n<li>必须同时拿起左右两根筷子；</li>\n<li>只有在两个邻居都没有进餐的情况下才允许进餐。</li>\n</ul>\n<pre><code class=\"language-c++\">#define N 5\n#define LEFT (i + N - 1) % N // 左邻居\n#define RIGHT (i + 1) % N    // 右邻居\n#define THINKING 0\n#define HUNGRY   1\n#define EATING   2\ntypedef int semaphore;\nint state[N];                // 跟踪每个哲学家的状态\nsemaphore mutex = 1;         // 临界区的互斥，临界区是 state 数组，对其修改需要互斥\nsemaphore s[N];              // 每个哲学家一个信号量\n\nvoid philosopher(int i) &#123;\n    while(TRUE) &#123;\n        think(i);\n        take_two(i);\n        eat(i);\n        put_two(i);\n    &#125;\n&#125;\n\nvoid take_two(int i) &#123;\n    down(&amp;mutex);\n    state[i] = HUNGRY;\n    check(i);\n    up(&amp;mutex);\n    down(&amp;s[i]); // 只有收到通知之后才可以开始吃，否则会一直等下去\n&#125;\n\nvoid put_two(i) &#123;\n    down(&amp;mutex);\n    state[i] = THINKING;\n    check(LEFT); // 尝试通知左右邻居，自己吃完了，你们可以开始吃了\n    check(RIGHT);\n    up(&amp;mutex);\n&#125;\n\nvoid eat(int i) &#123;\n    down(&amp;mutex);\n    state[i] = EATING;\n    up(&amp;mutex);\n&#125;\n\n// 检查两个邻居是否都没有用餐，如果是的话，就 up(&amp;s[i])，使得 down(&amp;s[i]) 能够得到通知并继续执行\nvoid check(i) &#123;         \n    if(state[i] == HUNGRY &amp;&amp; state[LEFT] != EATING &amp;&amp; state[RIGHT] !=EATING) &#123;\n        state[i] = EATING;\n        up(&amp;s[i]);\n    &#125;\n&#125;\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849\n</code></pre>\n<h3 id=\"读者-写者问题\"><a class=\"anchor\" href=\"#读者-写者问题\">#</a> 读者 - 写者问题</h3>\n<p>允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。</p>\n<p>一个整型变量 count 记录在对数据进行读操作的进程数量，一个互斥量 count_mutex 用于对 count 加锁，一个互斥量 data_mutex 用于对读写的数据加锁。</p>\n<pre><code class=\"language-c++\">typedef int semaphore;\nsemaphore count_mutex = 1;\nsemaphore data_mutex = 1;\nint count = 0;\n\nvoid reader() &#123;\n    while(TRUE) &#123;\n        down(&amp;count_mutex);\n        count++;\n        if(count == 1) down(&amp;data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问\n        up(&amp;count_mutex);\n        read();\n        down(&amp;count_mutex);\n        count--;\n        if(count == 0) up(&amp;data_mutex);\n        up(&amp;count_mutex);\n    &#125;\n&#125;\n\nvoid writer() &#123;\n    while(TRUE) &#123;\n        down(&amp;data_mutex);\n        write();\n        up(&amp;data_mutex);\n    &#125;\n&#125;\n1234567891011121314151617181920212223242526\n</code></pre>\n<h2 id=\"进程线程常见面试题\"><a class=\"anchor\" href=\"#进程线程常见面试题\">#</a> 进程线程常见面试题</h2>\n<h3 id=\"设计一下如何采用单线程的方式处理高并发\"><a class=\"anchor\" href=\"#设计一下如何采用单线程的方式处理高并发\">#</a> 设计一下如何采用单线程的方式处理高并发</h3>\n<ul>\n<li>在单线程模型中，可以采用 I/O 复用来提高单线程处理多个请求的能力，然后再采用事件驱动模型，基于异步回调来处理事件来</li>\n</ul>\n<h3 id=\"如何设计server使得能够接收多个客户端的请求\"><a class=\"anchor\" href=\"#如何设计server使得能够接收多个客户端的请求\">#</a> 如何设计 server，使得能够接收多个客户端的请求</h3>\n<ul>\n<li>单线程 + io 复用</li>\n<li>线程池</li>\n<li>多线程</li>\n</ul>\n<h3 id=\"死循环来连接时新建线程的方法效率有点低怎么改进\"><a class=\"anchor\" href=\"#死循环来连接时新建线程的方法效率有点低怎么改进\">#</a> 死循环 + 来连接时新建线程的方法效率有点低，怎么改进？</h3>\n<ul>\n<li>提前创建好一个线程池，用生产者消费者模型，创建一个任务队列，队列作为临界资源，有了新连接，就挂在到任务队列上，队列为空所有线程睡眠。</li>\n<li>改进死循环：使用 select epoll 这样的技术</li>\n</ul>\n<h3 id=\"怎么唤醒被阻塞的socket线程\"><a class=\"anchor\" href=\"#怎么唤醒被阻塞的socket线程\">#</a> 怎么唤醒被阻塞的 socket 线程？</h3>\n<p>当 socket 接受到数据，中断程序调用回调函数唤醒线程</p>\n<h3 id=\"有了进程为什么还要有线程\"><a class=\"anchor\" href=\"#有了进程为什么还要有线程\">#</a> 有了进程，为什么还要有线程？</h3>\n<ul>\n<li>\n<p>线程产生的原因：如果没有线程，那么一个进程在同一时间只能干一件事情。如果进程在执行过程中因为缺少资源而被阻塞，即使有些任务不需要当前缺少的资源，整个进程也会被挂起。</p>\n</li>\n<li>\n<p>线程的优势</p>\n<ul>\n<li>从资源上来讲，线程是一种非常 &quot;节俭&quot; 的多任务操作方式。在 linux 系统下，启动一个新的进程必须分配给它独立的地址空间，建立众多的数据表来维护它的代码段、堆栈段和数据段，这是一种 &quot;昂贵&quot; 的多任务工作方式。而线程可以共享进程的内存空间。</li>\n<li>从切换效率上来讲，运行于一个进程中的多个线程，它们之间使用相同的地址空间，而且线程间彼此切换所需时间也远远小于进程间切换所需要的时间。据统计，一个进程的开销大约是一个线程开销的 30 倍左右。</li>\n<li>从通信机制上来讲，线程间方便的通信机制。对不同进程来说，它们具有独立的数据空间，要进行数据的传递只能通过进程间通信的方式进行，这种方式不仅费时，而且很不方便。线程则不然，由于同一进城下的线程之间贡献数据空间，所以一个线程的数据可以直接为其他线程所用，这不仅快捷，而且方便。</li>\n</ul>\n</li>\n<li>\n<p>多线程程序作为一种多任务、并发的工作方式，还有如下优点：</p>\n<p>1、使多 CPU 系统更加有效。操作系统会保证当线程数不大于 CPU 数目时，不同的线程运行于不同的 CPU 上。</p>\n<p>2、改善程序结构。一个既长又复杂的进程可以考虑分为多个线程，成为几个独立或半独立的运行部分，这样的程序才会利于理解和修改。</p>\n</li>\n</ul>\n<h3 id=\"单核机器上写多线程程序是否需要考虑加锁为什么\"><a class=\"anchor\" href=\"#单核机器上写多线程程序是否需要考虑加锁为什么\">#</a> 单核机器上写多线程程序，是否需要考虑加锁，为什么？</h3>\n<ul>\n<li>在单核机器上写多线程程序，仍然需要线程锁。因为线程锁通常用来实现线程的同步和通信。在单核机器上的多线程程序，仍然存在线程同步的问题。因为在抢占式操作系统中，通常为每个线程分配一个时间片，当某个线程时间片耗尽时，操作系统会将其挂起，然后运行另一个线程。如果这两个线程共享某些数据，不使用线程锁的前提下，可能会导致共享数据修改引起冲突。</li>\n</ul>\n<h1 id=\"操作系统内存管理\"><a class=\"anchor\" href=\"#操作系统内存管理\">#</a> 操作系统内存管理</h1>\n<h2 id=\"虚拟内存\"><a class=\"anchor\" href=\"#虚拟内存\">#</a> 虚拟内存</h2>\n<ul>\n<li>目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存</li>\n<li>为了更好的管理内存，系统将内存抽象成地址空间。</li>\n<li>每个程序拥有自己的地址空间，这个地址空间被分为多个块，每一块为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都在物理内存中。</li>\n<li>当引用到不再物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的命令</li>\n<li>虚拟内存允许内存不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行。16 位地址可以映射 64KB 地址，32 位可以映射 4GB 地址。</li>\n</ul>\n<p>[外链图片转存失败，源站可能有防盗链机制，建议将图片保存下来直接上传 (img-MKdpIXFh-1602222903766)(C:\\Users\\free\\AppData\\Roaming\\Typora\\typora-user-images\\image-20200816131820778.png)]</p>\n<h3 id=\"分页系统地址映射\"><a class=\"anchor\" href=\"#分页系统地址映射\">#</a> 分页系统地址映射</h3>\n<p>内存管理单元（ <code>Memory Management Unit, MMU</code> ）管理着地址空间和物理内存的转换，其中的页表（ <code>Page table</code> ）存储着页（程序地址空间）和页框（物理内存空间）的映射表。</p>\n<p>一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。即（存储页面号 + 页内偏移量）</p>\n<p>下图的页表存放着 16 个页，这 16 个页需要用 4 个比特位来进行索引定位。例如对于虚拟地址（ <code>0010 0000 0000 0100</code> ），前 4 位是存储页面号 2，读取表项内容为（ <code>110 1</code> ），页表项最后一位表示是否存在于内存中，1 表示存在，0 表示不存在。后 12 位存储偏移量。这个页对应的页框的地址为 （ <code>110 0000 0000 0100</code> ）。</p>\n<p>[外链图片转存失败，源站可能有防盗链机制，建议将图片保存下来直接上传 (img-cwfAMftM-1602222903769)(C:\\Users\\free\\AppData\\Roaming\\Typora\\typora-user-images\\image-20200816131902810.png)]</p>\n<h3 id=\"页面置换算法\"><a class=\"anchor\" href=\"#页面置换算法\">#</a> 页面置换算法</h3>\n<p>在程序运行过程中，如果要访问的页面不在内存中，就发生<strong>缺页中断</strong>从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。</p>\n<p>页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。</p>\n<p>页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。</p>\n<h4 id=\"最佳optimal-replacement-algorithm-opt\"><a class=\"anchor\" href=\"#最佳optimal-replacement-algorithm-opt\">#</a> 最佳（Optimal replacement algorithm, OPT）</h4>\n<p>所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。</p>\n<p>是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。</p>\n<h4 id=\"最近最久未使用least-recently-usedlru\"><a class=\"anchor\" href=\"#最近最久未使用least-recently-usedlru\">#</a> 最近最久未使用（Least Recently Used，LRU）</h4>\n<p>虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。</p>\n<p>为了实现 LRU，需要在内存中维护一个所有页面的链表。<strong>当一个页面被访问时，将这个页面移到链表表头</strong>。这样就能保证链表表尾的页面是最近最久未访问的。</p>\n<p>因为每次<strong>访问都需要更新链表</strong>，因此这种方式实现的 LRU 代价很高。</p>\n<h4 id=\"最近未使用not-recently-usednru\"><a class=\"anchor\" href=\"#最近未使用not-recently-usednru\">#</a> 最近未使用（Not Recently Used，NRU）</h4>\n<p>每个页面都有两个状态位：R 与 M，当页面被访问时设置页面的 R=1，当页面被修改时设置 M=1。其中 R 位会定时被清零。可以将页面分成以下四类：</p>\n<ul>\n<li>R=0，M=0</li>\n<li>R=0，M=1</li>\n<li>R=1，M=0</li>\n<li>R=1，M=1</li>\n</ul>\n<p>当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出。</p>\n<p>NRU 优先换出已经被修改的<strong>脏页面（R=0，M=1）</strong>，而不是被频繁使用的<strong>干净页面（R=1，M=0）</strong></p>\n<h4 id=\"先入先出first-in-first-out-fifo\"><a class=\"anchor\" href=\"#先入先出first-in-first-out-fifo\">#</a> 先入先出（First In First Out, FIFO）</h4>\n<p>选择换出的页面是最先进入的页面。</p>\n<p>该算法会将那些经常被访问的页面换出，导致缺页率升高。</p>\n<h4 id=\"第二次机会算法\"><a class=\"anchor\" href=\"#第二次机会算法\">#</a> 第二次机会算法</h4>\n<p>FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改：</p>\n<ul>\n<li>当页面被访问 (读或写) 时设置该页面的 R 位为 1。</li>\n<li>需要替换的时候，检查最老页面的 R 位。</li>\n<li>如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；</li>\n<li>如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。</li>\n</ul>\n<h4 id=\"时钟clock\"><a class=\"anchor\" href=\"#时钟clock\">#</a> 时钟（Clock）</h4>\n<p>第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。</p>\n<h2 id=\"分段和分页\"><a class=\"anchor\" href=\"#分段和分页\">#</a> 分段和分页</h2>\n<ul>\n<li>分段通俗解释：linux 中就把一个程序分成代码段，数据段和堆栈段等。</li>\n<li>分页通俗解释：将这些段，例如代码段分成均匀的小块，然后这些给这些小块编号，然后就可以放到内存中去，由于编号了的，所以也不怕顺序乱</li>\n<li>然后我们就可以通过段号，页号和页内偏移找到程序的地址</li>\n</ul>\n<p>虚拟内存采用的是分页技术，也就是将地址空间划分成固定大小的页，每一页再与内存进行映射。</p>\n<p>下图为一个编译器在编译过程中建立的多个表，有 4 个表是动态增长的，如果使用分页系统的一维地址空间，动态增长的特点会导致覆盖问题的出现。</p>\n<p>分段的做法是把每个表分成段，<strong>一个段构成一个独立的地址空间</strong>。每个段的长度可以不同，并且可以动态增长。</p>\n<h2 id=\"段页式\"><a class=\"anchor\" href=\"#段页式\">#</a> 段页式</h2>\n<p>程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。</p>\n<h3 id=\"分页和分段的比较\"><a class=\"anchor\" href=\"#分页和分段的比较\">#</a> 分页和分段的比较</h3>\n<ul>\n<li>对程序员：分页透明，分段需要程序员显式划分每个段</li>\n<li>地址空间维度：分页地址是一维的，分段地址是二维（段名 + 段内地址）的</li>\n<li>大小是否可以改变：分页不可变，分段可变</li>\n<li>出现的原因：分页主要用于虚拟内存，从而获得更大的地址空间；分段是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护</li>\n</ul>\n<h1 id=\"操作系统linux\"><a class=\"anchor\" href=\"#操作系统linux\">#</a> 操作系统 linux</h1>\n<h2 id=\"linux文件系统\"><a class=\"anchor\" href=\"#linux文件系统\">#</a> Linux 文件系统</h2>\n<ul>\n<li><code>superblock</code> ：记录文件系统的整体信息，包括 inode 和 block 的总量，使用量和剩余量，以及文件系统的格式及相关信息等；</li>\n<li><code>block bitmap</code> ：记录 block 是否被使用的位图</li>\n<li><code>inode</code> ：一个文件占用一个 inode，记录文件的属性，同时记录此文件的内容所在的 block 编号；</li>\n<li><code>block</code> ：记录文件的内容，文件太大时，会占用多个 block</li>\n</ul>\n<p>[外链图片转存失败，源站可能有防盗链机制，建议将图片保存下来直接上传 (img-QwXtsh0d-1602222903774)(C:/Users/free/Desktop/ 面试 /interviewmd/assets/post/2018-04-02/BSD_disk.png)]</p>\n<p><strong>文件系统如何找到文件？</strong></p>\n<ul>\n<li>根据文件名，通过 Dictionary 的对应关系，找到文件对用的 inode number</li>\n<li>再根据 inode number 读取到文件的 inode table</li>\n<li>根据 inode table 中的 pointer 读取到相应的 blocks</li>\n</ul>\n<h2 id=\"linux文件是怎么存储的\"><a class=\"anchor\" href=\"#linux文件是怎么存储的\">#</a> Linux 文件是怎么存储的</h2>\n<p>一个文件由目录项，inode 和数据块组成。</p>\n<ul>\n<li>目录项：包括文件名和 inode 节点号</li>\n<li>inode：又称为文件索引节点，包含文件的基础信息以及数据块的指针</li>\n<li>数据块：包含文件的具体内容</li>\n</ul>\n<p>硬盘的最小存储单元为” 扇区 sector“，每个扇区存储 512 字节（0.5KB），操作系统读取硬盘时，一次性连续读取多个扇区，即一个” 块 block“。每个块最常见的大小为 4K，即 8 个扇区</p>\n<p>inode 存储文件的元信息，以及文件数据 block 的位置。</p>\n<ul>\n<li>\n<p>一个文件可以被存储在一个或者多个 block 中</p>\n</li>\n<li>\n<p>每个文件都会并且只会占用一个 inode，inode 可以指向该文件所在的 block</p>\n</li>\n<li>\n<p>想读取该文件，需要通过</p>\n<p>目录项</p>\n<p>的文件名来指向正确的 inode 号码才能读取</p>\n<ul>\n<li>** 目录项：** 当新建一个目录时，文件系统会分配一个 inode 和至少一个 block 给该目录。其中 inode 记录目录的相关权限和属性，并记录分配到的那块 block 目录。而 block 则是记录在这个目录下的文件名和其对应的 inode 号码数据，这就是数据项</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"文件处理命令待学习\"><a class=\"anchor\" href=\"#文件处理命令待学习\">#</a> 文件处理命令（待学习）</h2>\n<h3 id=\"grep\"><a class=\"anchor\" href=\"#grep\">#</a> grep</h3>\n<p>文本过滤器，可以使用正则表达式搜索文本，并把匹配的行打印出来。</p>\n<h3 id=\"sed\"><a class=\"anchor\" href=\"#sed\">#</a> sed</h3>\n<p>流编辑器，默认只处理模式空间，不处理原数据。处理时，把当前处理的行存储在临时缓冲区，称为 “模式空间”（pattern space），接着用 sed 命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送到屏幕，接着处理下一行，直到文件末尾。文件内容并没有改变，除非使用重定向存储输出。</p>\n<h3 id=\"awk\"><a class=\"anchor\" href=\"#awk\">#</a> awk</h3>\n<p>文本分析工具，相对于 grep 的查找，sed 的编辑，awk 在数据分析和生成数据显得尤为强大。awk 把文件逐行读入，以空格为默认分隔符将每行切片，切开的部分进行分析处理。</p>\n<h2 id=\"文件的三种时间\"><a class=\"anchor\" href=\"#文件的三种时间\">#</a> 文件的三种时间</h2>\n<ul>\n<li><code>mtime(Modification)</code> ：更改文件内容时会更新这个时间</li>\n<li><code>atime(Access)</code> ：读取文件，比如使用 less，more 读取时会更新这个时间</li>\n<li><code>ctime(Change)</code> ：在修改权限，写入文件、更改所有者、权限或者链接设置时随着 inode 的内容更改而更改，即文件状态最后一次被更改的时间</li>\n</ul>\n<h2 id=\"shell脚本\"><a class=\"anchor\" href=\"#shell脚本\">#</a> shell 脚本</h2>\n<p>待学习</p>\n<h2 id=\"硬链接和软连接\"><a class=\"anchor\" href=\"#硬链接和软连接\">#</a> 硬链接和软连接</h2>\n<h3 id=\"硬链接\"><a class=\"anchor\" href=\"#硬链接\">#</a> 硬链接</h3>\n<pre><code>ln [sourceFile] [linkName]\n</code></pre>\n<p>A 是 B 的硬链接，则 A 的目录项中的 inode 节点号于 B 的目录项中的 inode 节点号相同，即一个 inode 节点对应两个不同的文件名，A 和 B 对于系统来说是完全平等的。</p>\n<p>如果删除了其中一个，对另一个没有影响。每增加一个硬链接的文件名，inode 节点上的链接数增加 1，每删除一个就减 1，直到为 0，inode 节点和对应的 block 被回收。</p>\n<p>** 注意：** 文件和文件名是两个不同的东西， <code>rm A</code>  删除的只是 A 这个文件名，但是其对应的数据块（文件）并没有被删除，文件只有在 inode 节点链接数减少为 0 时才会被删除。</p>\n<h3 id=\"软连接\"><a class=\"anchor\" href=\"#软连接\">#</a> 软连接</h3>\n<pre><code>ln -s [sourceFile] [linkName]\n</code></pre>\n<p>A 是 B 的软连接，A 的目录项中的 inode 节点号和 B 的目录项中的 inode 节点号不同，A 和 B 指向不同的 inode，继而指向不同的数据库。但是 A 的数据块中存储的是 B 的路径名（可以根据这个路径名找到 B 的目录项）。A 和 B 之间是 “主从” 关系，如果 B 被删除了，A 依然存在，但指向的是一个无效链接。</p>\n<h3 id=\"区别\"><a class=\"anchor\" href=\"#区别\">#</a> 区别</h3>\n<h4 id=\"硬链接-2\"><a class=\"anchor\" href=\"#硬链接-2\">#</a> 硬链接</h4>\n<ul>\n<li>不能对目录创建硬链接，原因有几种，最重要的是：文件系统不能存在链接环（目录创建时的 &quot;…&quot; 除外，这个系统可以识别出来）, 存在环的后果会导致例如文件遍历等操作的混乱 (du，pwd 等命令的运作原理就是基于文件硬链接，顺便一提，ls -l 结果的第二列也是文件的硬链接数，即 inode 节点的链接数)</li>\n<li>不能对不同的文件系统创建硬链接，即两个文件名要在相同的文件系统下。</li>\n<li>不能对不存在的文件创建硬链接，由原理即可知原因。</li>\n</ul>\n<h4 id=\"软连接-2\"><a class=\"anchor\" href=\"#软连接-2\">#</a> 软连接</h4>\n<ul>\n<li>可以对目录创建软连接，遍历操作会忽略目录的软连接。</li>\n<li>可以跨文件系统</li>\n<li>可以对不存在的文件创建软连接，因为保存的只是一个字符串</li>\n</ul>\n",
            "tags": [
                "面试"
            ]
        },
        {
            "id": "http://zhanglin233.github.io/2021/12/25/computer-science/interview/%E9%9D%A2%E8%AF%95%E5%B8%B8%E9%97%AE%E9%97%AE%E9%A2%98/",
            "url": "http://zhanglin233.github.io/2021/12/25/computer-science/interview/%E9%9D%A2%E8%AF%95%E5%B8%B8%E9%97%AE%E9%97%AE%E9%A2%98/",
            "title": "后端面试常问问题",
            "date_published": "2021-12-25T13:13:46.552Z",
            "content_html": "<h1 id=\"java\"><a class=\"anchor\" href=\"#java\">#</a> java</h1>\n<h2 id=\"int和integer的区别\"><a class=\"anchor\" href=\"#int和integer的区别\">#</a> int 和 Integer 的区别</h2>\n<ol>\n<li>Integer 是 int 的包装类，int 则是 java 的一种基本数据类型</li>\n<li>Integer 变量必须实例化后才能使用，而 int 变量不需要</li>\n<li>Integer 实际是对象的引用，当 new 一个 Integer 时，实际上是生成一个指针指向此对象；而 int 则是直接存储数据值</li>\n<li>Integer 的默认值是 null，int 的默认值是 0</li>\n</ol>\n<h2 id=\"string-是最基本的数据类型吗\"><a class=\"anchor\" href=\"#string-是最基本的数据类型吗\">#</a> String 是最基本的数据类型吗？</h2>\n<p>不是，他是引用类型。基本数据类型只有 8 个，char、byte、short、int、long、float、double 和 boolean。</p>\n<p>【整型】byte、short、int 和 long，分别是 1、2、4 和 8 字节。</p>\n<p>【浮点型】float 和 double，分别是 4 和 8 字节。</p>\n<p>【字符型】char，2 字节。</p>\n<p>【布尔型】boolean，只有 true 和 false。</p>\n<h2 id=\"请问jdk和jre的区别是什么\"><a class=\"anchor\" href=\"#请问jdk和jre的区别是什么\">#</a> <strong>请问 JDK 和 JRE 的区别是什么？</strong></h2>\n<p>解析：</p>\n<p>Java 运行时环境 (JRE) 是将要执行 Java 程序的 Java 虚拟机。它同时也包含了执行 applet 需要的浏览器插件。Java 开发工具包 (JDK) 是完整的 Java 软件开发包，包含了 JRE，编译器和其他的工具 (比如：JavaDoc，Java 调试器)，可以让开发者开发、编译、执行 Java 应用程序。</p>\n<h2 id=\"多线程中的i线程安全吗请简述一下原因\"><a class=\"anchor\" href=\"#多线程中的i线程安全吗请简述一下原因\">#</a> <strong>多线程中的 i++ 线程安全吗？请简述一下原因？</strong></h2>\n<p>解析：</p>\n<p>不安全。i<ins> 不是原子性操作。i</ins> 分为读取 i 值，对 i 值加一，再赋值给 i++，执行期中任何一步都是有可能被其他线程抢占的。</p>\n<h2 id=\"深拷贝和浅拷贝是什么\"><a class=\"anchor\" href=\"#深拷贝和浅拷贝是什么\">#</a> 深拷贝和浅拷贝是什么？</h2>\n<p>解析：</p>\n<p>简单来讲就是复制、克隆。</p>\n<p>Person p=new Person (“张三 &quot;);</p>\n<p>浅拷贝就是对对象中的数据成员进行简单赋值，如果存在动态成员或者指针就会报错。而且，如果有引用类型的变量，新生成的对象和被拷贝的对象的这个属性会指向同一个地方，没有解耦，会影响对方，2 个对象会拥有一样的值（穿一条裤子）。对基本数据类型来说，两边是独立的。</p>\n<p>深拷贝就是对对象中存在的动态成员或指针重新开辟内存空间。而且，如果有引用类型的变量，新生成的对象和被拷贝的对象的这个属性会指向 2 个地方，解耦了，不会影响对方，2 个对象分别做修改的话，不会影响到对方。</p>\n<h2 id=\"面向对象的特征有哪些方面\"><a class=\"anchor\" href=\"#面向对象的特征有哪些方面\">#</a> 面向对象的特征有哪些方面？</h2>\n<p>解析：</p>\n<p>面向对象的特征主要有以下几个方面：</p>\n<p>1) 抽象：抽象就是忽略一个主题中与当前目标无关的那些方面，以便更充分地注意与当前目标有关的方面。抽象并不打算了解全部问题，而只是选择其中的一部分，暂时不用部分细节。抽象包括两个方面，一是过程抽象，二是数据抽象。</p>\n<p>2) 继承：继承是一种联结类的层次模型，并且允许和鼓励类的重用，它提供了一种明确表述共性的方法。对象的一个新类可以从现有的类中派生，这个过程称为类继承。新类继承了原始类的特性，新类称为原始类的派生类（子类），而原</p>\n<p>始类称为新类的基类（父类）。派生类可以从它的基类那里继承方法和实例变量，并且类可以修改或增加新的方法使之更适合特殊的需要。</p>\n<p>3) 封装：封装是把过程和数据包围起来，对数据的访问只能通过已定义的界面。面向对象计算始于这个基本概念，即现实世界可以被描绘成一系列完全自治、封装的对象，这些对象通过一个受保护的接口访问其他对象。</p>\n<p>4) 多态性：多态性是指允许不同类的对象对同一消息作出响应。多态性包括参数化多态性和包含多态性。多态性语言具有灵活、抽象、行为共享、代码共享的优势，很好的解决了应用程序函数同名问题。</p>\n<h2 id=\"简述mybatis的xml映射文件和mybatis内部数据结构之间的映射关系\"><a class=\"anchor\" href=\"#简述mybatis的xml映射文件和mybatis内部数据结构之间的映射关系\">#</a> <strong>简述 Mybatis 的 Xml 映射文件和 Mybatis 内部数据结构之间的映射关系？</strong></h2>\n<p>解析：</p>\n<p>Mybatis 将所有 Xml 配置信息都封装到 All-In-One 重量级对象 Configuration 内部。在 Xml 映射文件中， <code>&lt;parameterMap&gt;</code>  标签会被解析为 <code>ParameterMap</code>  对象，其每个子元素会被解析为 <code>ParameterMapping</code>  对象。 <code>&lt;resultMap&gt;</code>  标签会被解析为 <code>ResultMap</code>  对象，其每个子元素会被解析为 <code>ResultMapping</code>  对象。每一个 <code>&lt;select&gt;</code> 、 <code>&lt;insert&gt;</code> 、 <code>&lt;update&gt;</code> 、 <code>&lt;delete&gt;</code>  标签均会被解析为 MappedStatement 对象，标签内的 sql 会被解析为 BoundSql 对象。</p>\n<h1 id=\"计网\"><a class=\"anchor\" href=\"#计网\">#</a> 计网</h1>\n<h2 id=\"tcpudp\"><a class=\"anchor\" href=\"#tcpudp\">#</a> tcp/udp</h2>\n<h3 id=\"1-tcpudp-协议\"><a class=\"anchor\" href=\"#1-tcpudp-协议\">#</a> <strong>1. tcp/udp 协议</strong></h3>\n<p>tcp/udp 是传输层协议。是十分常用的网络协议.TCP 面向连接 （三次握手），UDP 是无连接的，即发送数据之前不需要建立连接。</p>\n<p>TCP 提供可靠的服务。也就是说，通过 TCP 连接传送的数据，无差错，不丢失，不重复，且按序到达；UDP 尽最大努力交付，即不保证可靠交付</p>\n<p>TCP 面向字节流，实际上是 TCP 把数据看成一连串无结构的字节流；UDP 是面向报文的</p>\n<p>UDP 没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如 IP 电话，实时视频会议等）</p>\n<p><strong>1.1 tcp 三次握手、四次挥手</strong></p>\n<h4 id=\"三次握手建立连接\"><a class=\"anchor\" href=\"#三次握手建立连接\">#</a> <strong>三次握手建立连接</strong></h4>\n<p><img data-src=\"https://img-blog.csdnimg.cn/20200411140619805.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMDcxMDY4,size_16,color_FFFFFF,t_70\" alt=\"img\" /></p>\n<h5 id=\"第一次握手\"><a class=\"anchor\" href=\"#第一次握手\">#</a> <strong>第一次握手 :</strong></h5>\n<p><strong>client :</strong> 客户端向服务端发送连接请求 SYN 包 (发送连接请求)(SYN=1, 同时选择一个初始序号 seq=x) 后，客户端进入 SYN-SENT 状态，等待服务器确认回复.</p>\n<p>**server 😗* 当服务端还没有接收到客户端的连接请求时，服务端处于 LISTEN 状态.</p>\n<h5 id=\"第二次握手\"><a class=\"anchor\" href=\"#第二次握手\">#</a> <strong>第二次握手 :</strong></h5>\n<p><strong>server :</strong> 当服务端收到客户端的连接请求时 (收到 syn 包), 为新的连接请求创建新的通信 socket, 此时服务端必须确认客户端的 SYN 请求 (回复确认序号 ack = x + 1), 确认序号有效 ACK=1, 因为连接是双向的，所以服务端也向客户端发送连接请求 SYN 包 (SYN = 1, 为自己选择一个初始序号 seq = y), 即服务端向客户端发送 ACK+SYN 包，服务端进入 SYN_RCVD 状态。当第二次握手完成，还没进行第三次握手时，此时 TCP 连接的状态称之为半连接状态.</p>\n<h5 id=\"第三次握手\"><a class=\"anchor\" href=\"#第三次握手\">#</a> <strong>第三次握手 :</strong></h5>\n<p>​    <strong>client :</strong> 当客户端收到服务端回复的 SYN+ACK 包时，确认建立连接 (客户端这边已经没什么问题了，可以通信了), 并回复给服务端确认信息 ACK 包 (seq = x + 1, ack = y+1), 客户端的进入 ESTABLISHED 状态，完成连接</p>\n<p>​    <strong>server :</strong> 当服务端收到客户端发送的 ACK 包后，确认客户端连接就绪，可以开始通行，进入 ESTABLISHED 状态</p>\n<h4 id=\"四次挥手断开连接\"><a class=\"anchor\" href=\"#四次挥手断开连接\">#</a> <strong>四次挥手断开连接</strong></h4>\n<p><img data-src=\"https://img-blog.csdnimg.cn/20200412110254633.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMDcxMDY4,size_16,color_FFFFFF,t_70\" alt=\"img\" /> 图片来源于网络</p>\n<h5 id=\"第一次挥手\"><a class=\"anchor\" href=\"#第一次挥手\">#</a> <strong>第一次挥手 :</strong></h5>\n<p><strong>client :</strong> 当客户端确定不再需要发送数据时，调用 close (sockfd) /shutdown (sockfd, SHUT_WR) (两者的区别以及用法下面说). 客户端会向服务端发送 FIN 包 (FIN=1, seq = u)(u 就是客户端之前收到的数据的最后一个字节的序号 + 1), 客户端进入 FIN_WAIT1 状态. (注意 : TCP 协议规定，FIN 报文段就算没有数据，也需要消耗一个序号)</p>\n<p><strong>server :</strong> 当服务端未收到客户端发送的 FIN 包时，一直处于 ESTABLISHED 状态</p>\n<h5 id=\"第二次挥手\"><a class=\"anchor\" href=\"#第二次挥手\">#</a> <strong>第二次挥手 :</strong></h5>\n<p><strong>server :</strong> 当服务端收到客户端发来的 FIN 包后，知道客户端不会再发送数据了，也就不需要接受，先调用 close (sockfd) /shutdown (sockfd, SHUT_RD), 再确认回复客户端，即 (ACK=1, ack = u+1), 并且带上自己的序列号 seq=v, 此时服务端的进入了 CLOSE_WAIT 状态. TCP 服务端就通知高层的应用进程，客户端不会再向服务端发送数据了，此时 TCP 通信的连接状态就称为半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个 CLOSE_WAIT 状态持续的时间.</p>\n<p><strong>client :</strong> 当客户端收到服务器的确认请求 (ACK 包) 后，此时，客户端就进入 FIN_WAIT2 状态，等待服务器发送 FIN (在这之前还需要接收服务器发送的最后的数据)</p>\n<h5 id=\"第三次挥手\"><a class=\"anchor\" href=\"#第三次挥手\">#</a> <strong>第三次挥手 :</strong></h5>\n<p><strong>server :</strong> 服务端将最后的数据发送完毕后，再不需要发送数据了，就调用 shutdown (sockfd, SHUT_WR) , 再向客户端发送 FIN 包，由于在半关闭状态，服务器很可能又向客户端发送了一些数据，假定此时的序列号为 seq=w，即 FIN 包 (ACK=1, seq=w, ack=u+1). 此时，服务端就进入了 LAST_ACK (最后确认) 状态，等待客户端的确认.</p>\n<h5 id=\"第四次挥手\"><a class=\"anchor\" href=\"#第四次挥手\">#</a> <strong>第四次挥手 :</strong></h5>\n<p><strong>client :</strong> 当客户端收到服务端的连接释放请求 (FIN 包) 时，必须发出确认，ACK=1，ack=w+1, 而自己的序列号是 seq=u+1, 此时，客户端就进入了 TIME_WAIT 状态。注意：此时 TCP 连接还没有释放，必须经过 2 倍的 MSL (最长报文段寿命) 的时间后，当客户端释放连接后，才进入 CLOSED 状态.</p>\n<p><strong>server :</strong> 服务端只要收到了客户端发出的确认 (ACK 包), 立即进入 CLOSED 状态。同样，释放 TCB 连接后，就结束了这次的 TCP 连接。可以看到，服务端结束 TCP 连接的时间要比客户端早一些.</p>\n<p><strong>注意 :</strong> 需要注意的是，四次挥手可以是由客户端首先发送 FIN 包触发，也可以由服务端首先发送 FIN 包触发.</p>\n<p>tcp 通过三次握手建立连接，通过四次挥手断开连接. UDP 则是面向无连接的，不需要建立连接.</p>\n<h3 id=\"12-tcp-流控制\"><a class=\"anchor\" href=\"#12-tcp-流控制\">#</a> <strong>1.2 tcp 流控制</strong></h3>\n<p>连续 ARQ 协议使得 TCP 的帧可以在滑动窗口大小范围内连续的流动。通过拥塞窗口、拥塞避免、慢开始等算法控制 TCP 的流.</p>\n<h3 id=\"13-持续计时器\"><a class=\"anchor\" href=\"#13-持续计时器\">#</a> <strong>1.3 持续计时器</strong></h3>\n<p>当发送方接受到窗口值为 0 的 ACK 报文，需要启动一个计时器等待接收方再次发送窗口大小非 0 的 ACK 报文 (TCP 中，仅仅包含确认信息的报文不需要确认和重传). 若没有计时器，可能在窗口非 0 的 ACK 报文丢失后，俩方都处在等待状态中。当持续计时器结束后，发送方会发送一个特殊的探测报文，促使对方重传一个 ACK 报文.</p>\n<h3 id=\"14-停止等待协议-arq-协议\"><a class=\"anchor\" href=\"#14-停止等待协议-arq-协议\">#</a> <strong>1.4 停止等待协议、ARQ 协议</strong></h3>\n<ul>\n<li><strong>停止等待协议</strong>是数据链路层协议。它规定只有收到正确的确认帧后，才能新发送状态变量以及数据帧.</li>\n<li><strong>ARQ 协议 (Automatic Repeat-reQuest)</strong> 是数据链路层的纠错协议，它有停止等待 ARQ 协议和连续 ARQ 协议.</li>\n<li><strong>停止等待 ARQ 协议</strong>：每次发送一个报文，确认后发送下一个报文，发送窗口和接受窗口均是 1，停止等待 ARQ 所需缓冲区小但是效率低.</li>\n<li><strong>连续 ARQ 协议</strong>：即回退 n 帧 GBN 以及选择性重传 ARQ ，是滑动窗口与请求重发技术的结合。它可以连续发送若干信息帧，而不用等前一帧被确认，大大提升了发送效率。但需要发送方设置一个重发表，存放待确认的帧，收到确认帧后从重发表中删除帧，需要更大的存储空间.</li>\n</ul>\n<h3 id=\"请你说一下为什么tcp可靠哪些方法保证可靠\"><a class=\"anchor\" href=\"#请你说一下为什么tcp可靠哪些方法保证可靠\">#</a> 请你说一下为什么 tcp 可靠，哪些方法保证可靠</h3>\n<p>解析：</p>\n<p>[1] 确认和重传机制</p>\n<p>建立连接时三次握手同步双方的 “序列号 + 确认号 + 窗口大小信息”，是确认重传、流控的基础</p>\n<p>传输过程中，如果 Checksum 校验失败、丢包或延时，发送端重传。</p>\n<p>[2] 数据排序</p>\n<p>TCP 有专门的序列号 SN 字段，可提供数据 re-order</p>\n<p>[3] 流量控制</p>\n<p>滑动窗口和计时器的使用。TCP 窗口中会指明双方能够发送接收的最大数据量，发送方通过维持一个发送滑动窗口来确保不会发生由于发送方报文发送太快接收方无法及时处理的问题。</p>\n<p>[4] 拥塞控制</p>\n<p>TCP 的拥塞控制由 4 个核心算法组成：</p>\n<p>“慢启动”（Slow Start）</p>\n<p>“拥塞避免”（Congestion avoidance）</p>\n<p>“快速重传”（Fast Retransmit）</p>\n<p>“快速恢复”（Fast Recovery）</p>\n<h3 id=\"15-滑动窗口-慢开始-拥塞避免-快重传-快恢复-可靠性-顺序传输-tcp-bbr-拥塞算法\"><a class=\"anchor\" href=\"#15-滑动窗口-慢开始-拥塞避免-快重传-快恢复-可靠性-顺序传输-tcp-bbr-拥塞算法\">#</a> <strong>1.5 滑动窗口、慢开始、拥塞避免、快重传、快恢复、可靠性、顺序传输、TCP BBR 拥塞算法</strong></h3>\n<p><img data-src=\"https://pic2.zhimg.com/80/v2-7b878e527000b4ed0bd6672638249ecd_720w.jpg\" alt=\"img\" /></p>\n<ul>\n<li><strong>滑动窗口</strong>：滑动窗口协议是用来改善吞吐量的一种技术，即容许发送方在接收任何应答之前传送附加的包。接收方告诉发送方在某一时刻能送多少包（称窗口尺寸）。</li>\n<li><strong>慢开始</strong>：将拥塞窗口值设置为 1，发送端每接收到一个 ACK 就将拥塞窗口增加 1 直到达到拥塞门限值 (ssthresh，初始值为 16).</li>\n<li><strong>拥塞门限 (ssthresh)</strong>: 慢开始算法的拥塞窗口最大值.</li>\n<li><strong>拥塞窗口 (cwnd)</strong>: 取决于网络的拥塞程度，且在不断的变化，只要网络没有出现拥塞，发送方就将拥塞窗口调大一些，而只要出现拥塞，则减小一些。发送窗口始终小于拥塞窗口（在接受窗口更小时小于拥塞窗口).<br />\n 接受窗口 (rwnd): 接受方根据自己的接受能力（缓存限制）设置了接受窗口 rwnd, 并将其写入 tcp 首部字段中.</li>\n<li><strong>拥塞避免算法</strong>：让拥塞窗口缓慢增长，即每经过一个往返时间 RTT 就把发送方的拥塞窗口 cwnd 加 1，而不是加倍。这样拥塞窗口按线性规律缓慢增长.</li>\n<li><strong>快重传和快恢复 (Fast Retransmit and Recovery)</strong>: 可以提高网络的吞吐量。接收机接收到一个不按顺序的数据段，它会立即给发送机发送一个重复确认。如果发送机接收到三个重复确认，它会假定确认件指出的数据段丢失了，并立即重传这些丢失的数据段。有了 FRR，就不会因为重传时要求的暂停被耽误。没有 FRR，如果数据包丢失了，TCP 将会使用定时器来要求传输暂停.</li>\n<li><strong>快恢复算法</strong>：与快重传配合使用，当发送方连续收到三个重复确认时，就执行乘法减小算法，把慢开始门限 ssthresh 减半。这是为了预防网络发生拥塞。请注意，接下去就不再执行慢开始算法了。由于发送方现在认为网络很可能没有发生拥塞，不执行慢开始而是把 cwnd 值设置为慢开始门限 ssthresh 减半后的数值，然后开始执行拥塞避免算法，使拥塞窗口慢慢的线性的增大。</li>\n<li><strong>BBR 拥塞算法</strong>: Google 的 TCP BBR 算法，优化了 TCP 的吞吐量.</li>\n</ul>\n<h3 id=\"16-滑动窗口大小怎么确定\"><a class=\"anchor\" href=\"#16-滑动窗口大小怎么确定\">#</a> <strong>1.6 滑动窗口大小怎么确定？</strong></h3>\n<p>分为接受窗口和发送窗口。接受窗口的值根据缓存大小确定。接受方将接受窗口大小放在 TCP 报文首部。发送法根据接受窗口和拥塞窗口的大小（最小值）确定发送窗口的大小。而拥塞窗口的大小则受限于网络情况，根据传输过程动态的确定.</p>\n<h3 id=\"17-tcp-udp-怎么判断客户端关闭\"><a class=\"anchor\" href=\"#17-tcp-udp-怎么判断客户端关闭\">#</a> <strong>1.7 tcp、udp 怎么判断客户端关闭？</strong></h3>\n<p>根据接受到的数据包长度判断，如果接受到的报文长度是 0，则意味着客户端已经断开了连接.</p>\n<h3 id=\"18-tcp-udp-的区别\"><a class=\"anchor\" href=\"#18-tcp-udp-的区别\">#</a> <strong>1.8 tcp、udp 的区别？</strong></h3>\n<p>tcp 是面向连接的、可靠的，而 udp 是无连接、不可靠的.</p>\n<p>tcp 保证数据的正确性、顺序性。而 udp 不保证. TCP 是流模式的，而 UDP 是数据包模式的.</p>\n<h3 id=\"19-udp-的实际应用场景\"><a class=\"anchor\" href=\"#19-udp-的实际应用场景\">#</a> <strong>1.9 udp 的实际应用场景？</strong></h3>\n<p>UDP 报文常用于效率要求高，而准确性相对低的场景。如视频直播、聊天等.</p>\n<h3 id=\"110-time_wait-是什么状态它有什么作用为什么持续-2-msl\"><a class=\"anchor\" href=\"#110-time_wait-是什么状态它有什么作用为什么持续-2-msl\">#</a> <strong>1.10 time_wait 是什么状态？它有什么作用？为什么持续 2 MSL？</strong></h3>\n<p>time_wait: tcp 连接后，在四次握手之后，先发 FIN 标志位的一端就会进入 time_wait 状态。它的作用有俩个:</p>\n<ul>\n<li>确保最后一个确认报文能够到达。如果没能到达，服务端会重发 FIN 请求，等待一段时间没有重发，说明服务端已经 CLOSED 了。若有重发，客户端将重发 last ack 报文.</li>\n<li>等待一段时间 ( 2MSL ），确保此次连接过程中所有报文都从网络中消失。使得新的连接不会出现旧的连接请求报文.</li>\n</ul>\n<h3 id=\"111-请你说一说tcp的三次握手\"><a class=\"anchor\" href=\"#111-请你说一说tcp的三次握手\">#</a> 1.11 请你说一说 TCP 的三次握手？</h3>\n<p><img data-src=\"https://uploadfiles.nowcoder.com/images/20190314/311436_1552561665620_E7A5C9C77901F4FC171124336780AA75\" alt=\"img\" /></p>\n<p>第一次握手：建立连接时，客户端发送 syn 包（syn=j）到服务器，并进入 SYN_SENT 状态，等待服务器确认；SYN：同步序列编号（Synchronize Sequence Numbers）。</p>\n<p>第二次握手：服务器收到 syn 包，必须确认客户的 SYN（ack=j+1），同时自己也发送一个 SYN 包（syn=k），即 SYN+ACK 包，此时服务器进入 SYN_RECV 状态；</p>\n<p>第三次握手：客户端收到服务器的 SYN+ACK 包，向服务器发送确认包 ACK (ack=k+1），此包发送完毕，客户端和服务器进入 ESTABLISHED（TCP 连接成功）状态，完成三次握手。</p>\n<h3 id=\"请你说一下在浏览器中输入一个网址它的运行过程是怎样的\"><a class=\"anchor\" href=\"#请你说一下在浏览器中输入一个网址它的运行过程是怎样的\">#</a> 请你说一下在浏览器中输入一个网址它的运行过程是怎样的？</h3>\n<p>解析：</p>\n<p>1、查询 DNS，获取域名对应的 IP。</p>\n<p>​\t（1）检查浏览器缓存、检查本地 hosts 文件是否有这个网址的映射，如果有，就调用这个 IP 地址映射，解析完成。</p>\n<p>​\t（2）如果没有，则查找本地 DNS 解析器缓存是否有这个网址的映射，如果有，返回映射，解析完成。</p>\n<p>​\t（3）如果没有，则查找填写或分配的首选 DNS 服务器，称为本地 DNS 服务器。服务器接收到查询时：</p>\n<p>​\t如果要查询的域名包含在本地配置区域资源中，返回解析结果，查询结束，此解析具有权威性。</p>\n<p>​\t如果要查询的域名不由本地 DNS 服务器区域解析，但服务器缓存了此网址的映射关系，返回解析结果，查询结束，此解析不具有权威性。</p>\n<p>​\t（4）如果本地 DNS 服务器也失效：</p>\n<p>​\t如果未采用转发模式（迭代），本地 DNS 就把请求发至 13 台根 DNS，根 DNS 服务器收到请求后，会判断这个域名（<span class=\"exturl\" data-url=\"aHR0cDovL3huLS1idnMuY29t\">如.com</span>）是谁来授权管理，并返回一个负责该顶级域名服务器的 IP，本地 DNS 服务器收到顶级域名服务器 IP 信息后，继续向该顶级域名服务器 IP 发送请求，该服务器如果无法解析，则会找到负责这个域名的下一级 DNS 服务器（如<span class=\"exturl\" data-url=\"aHR0cDovL2JhaWR1LmNvbS8=\"> http://baidu.com</span>）的 IP 给本地 DNS 服务器，循环往复直至查询到映射，将解析结果返回本地 DNS 服务器，再由本地 DNS 服务器返回解析结果，查询完成。</p>\n<p>​\t如果采用转发模式（递归），则此 DNS 服务器就会把请求转发至上一级 DNS 服务器，如果上一级 DNS 服务器不能解析，则继续向上请求。最终将解析结果依次返回本地 DNS 服务器，本地 DNS 服务器再返回给客户机，查询完成。</p>\n<p>​\t2、得到目标服务器的 IP 地址及端口号（http 80 端口，https 443 端口），会调用系统库函数 socket，请求一个 TCP 流套接字。客户端向服务器发送 HTTP 请求报文：</p>\n<p>​\t（1）应用层：客户端发送 HTTP 请求报文。</p>\n<p>​\t（2）传输层：（加入源端口、目的端口）建立连接。实际发送数据之前，三次握手客户端和服务器建立起一个 TCP 连接。</p>\n<p>​\t（3）网络层：（加入 IP 头）路由寻址。</p>\n<p>​\t（4）数据链路层：（加入 frame 头）传输数据。</p>\n<p>​\t（5）物理层：物理传输 bit。</p>\n<p>​\t3、服务器端经过物理层→数据链路层→网络层→传输层→应用层，解析请求报文，发送 HTTP 响应报文。</p>\n<p>​\t4、关闭连接，TCP 四次挥手。</p>\n<p>​\t5、客户端解析 HTTP 响应报文，浏览器开始显示 HTML</p>\n<h2 id=\"http\"><a class=\"anchor\" href=\"#http\">#</a> HTTP</h2>\n<h3 id=\"请你说一说http请求报文\"><a class=\"anchor\" href=\"#请你说一说http请求报文\">#</a> 请你说一说 http 请求报文</h3>\n<p>解析：</p>\n<p>http 请求报文：</p>\n<p><img data-src=\"https://uploadfiles.nowcoder.com/images/20190314/311436_1552561821939_7986A5D29E20ECF79B0DB0AB97F16945\" alt=\"img\" /></p>\n<p>1、请求方法</p>\n<p>GET：请求获取 Request——URL 所标识的资源</p>\n<p>POST：在 Request——URL 所标识的资源后附加资源</p>\n<p>HEAD：请求获取由 Request——URL 所标识的资源的响应消息报头</p>\n<p>PUT：请求服务器存储一个资源，由 Request——URL 作为其标识</p>\n<p>DELETE：请求服务器删除由 Request——URL 所标识的资源</p>\n<p>TRACE：请求服务器回送收到的请求信息（用于测试和诊断）</p>\n<p>CONNECT：保留</p>\n<p>OPTIONS：请求查询服务器性能</p>\n<p>2、URL</p>\n<p>URI 全名为 Uniform Resource Indentifier（统一资源标识），用来唯一的标识一个资源，是一个通用的概念，URI 由两个主要的子集 URL 和 URN 组成。URL 全名为 Uniform Resource Locator（统一资源定位），通过描述资源的位置来标识资源。URN 全名为 Uniform Resource Name（统一资源命名），通过资源的名字来标识资源，与其所处的位置无关，这样即使资源的位置发生变动，其 URN 也不会变化。0.</p>\n<p>3、协议版本</p>\n<p>格式为 HTTP / 主版本号。次版本号，常用为：HTTP/1.1 HTTP/1.0</p>\n<p>4、请求头部</p>\n<p>Host：接受请求的服务器地址，可以是 IP 或者是域名</p>\n<p>User-Agent：发送请求的应用名称</p>\n<p>Connection：指定与连接相关的属性，例如（Keep_Alive，长连接）</p>\n<p>Accept-Charset：通知服务器端可以发送的编码格式</p>\n<p>Accept-Encoding：通知服务器端可以发送的数据压缩格式</p>\n<p>Accept-Language：通知服务器端可以发送的语言</p>\n<h3 id=\"说一下-get-和-post-的区别\"><a class=\"anchor\" href=\"#说一下-get-和-post-的区别\">#</a> 说一下 GET 和 POST 的区别？</h3>\n<ul>\n<li>Get 方法的含义是请求从服务器获取资源，这个资源可以是静态的文本、页面、图片视频等。</li>\n<li>而 POST 方法则是相反操作，它向 URI 指定的资源提交数据，数据就放在报文的 body 里。</li>\n</ul>\n<ul>\n<li>\n<p>GET 在浏览器回退时是无害的，而 POST 会再次提交请求。</p>\n</li>\n<li>\n<p>GET 产生的 URL 地址可以被 Bookmark，而 POST 不可以。</p>\n</li>\n<li>\n<p>GET 请求会被浏览器主动 cache，而 POST 不会，除非手动设置。</p>\n</li>\n<li>\n<p>GET 请求只能进行 url 编码，而 POST 支持多种编码方式。</p>\n</li>\n<li>\n<p>GET 请求参数会被完整保留在浏览器历史记录里，而 POST 中的参数不会被保留。</p>\n</li>\n<li>\n<p>GET 请求在 URL 中传送的参数是有长度限制的，而 POST 么有。</p>\n</li>\n<li>\n<p>对参数的数据类型，GET 只接受 ASCII 字符，而 POST 没有限制。</p>\n</li>\n<li>\n<p>GET 比 POST 更不安全，因为参数直接暴露在 URL 上，所以不能用来传递敏感信息。</p>\n</li>\n<li>\n<p>GET 参数通过 URL 传递，POST 放在 Request body 中。</p>\n</li>\n<li>\n<p>GET 和 POST 还有一个重大区别，简单的说：</p>\n</li>\n<li>\n<p>GET 产生一个 TCP 数据包；POST 产生两个 TCP 数据包。</p>\n</li>\n<li>\n<p>长的说：</p>\n</li>\n<li>\n<p>对于 GET 方式的请求，浏览器会把 http header 和 data 一并发送出去，服务器响应 200（返回数据）；</p>\n</li>\n<li>\n<p>而对于 POST，浏览器先发送 header，服务器响应 100 continue，浏览器再发送 data，服务器响应 200 ok（返回数据）。</p>\n<p>也就是说，GET 只需要汽车跑一趟就把货送到了，而 POST 得跑两趟，第一趟，先去和服务器打个招呼 “嗨，我等下要送一批货来，你们打开门迎接我”，然后再回头把货送过去。</p>\n<p>因为 POST 需要两步，时间上消耗的要多一点，看起来 GET 比 POST 更有效。</p>\n</li>\n</ul>\n<h4 id=\"get-和-post-方法都是安全和幂等的吗\"><a class=\"anchor\" href=\"#get-和-post-方法都是安全和幂等的吗\">#</a> GET 和 POST 方法都是安全和幂等的吗？</h4>\n<p>先说明下安全和幂等的概念：</p>\n<ul>\n<li>在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。</li>\n<li>所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。</li>\n</ul>\n<p>那么很明显 GET 方法就是安全且幂等的，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。</p>\n<p>POST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创建多个资源，所以不是幂等的。</p>\n<h3 id=\"http和https的区别\"><a class=\"anchor\" href=\"#http和https的区别\">#</a> Http 和 Https 的区别</h3>\n<ul>\n<li>HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP</li>\n<li>网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。</li>\n<li>HTTP 的端口号是 80，HTTPS 的端口号是 443。</li>\n<li>HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。</li>\n</ul>\n<p>HTTP 由于是明文传输，所以安全上存在以下三个风险：</p>\n<ol>\n<li>窃听风险，比如通信链路上可以获取通信内容</li>\n<li>篡改风险</li>\n<li>冒充风险，比如冒充淘宝网站</li>\n</ol>\n<p><img data-src=\"https://img-blog.csdnimg.cn/a7fa82cc355243b8a74f220d085e984c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBALSDlnIjlnIjnmoTnp5HnoJTml6XorrA=,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\" /></p>\n<p>HTTPS 在 HTTP 与 TCP 层之间加入了 SSL/TLS 协议。</p>\n<h3 id=\"http10-http11-http2-http3\"><a class=\"anchor\" href=\"#http10-http11-http2-http3\">#</a> HTTP/1.0 HTTP/1.1、HTTP/2、HTTP/3</h3>\n<h4 id=\"http10\"><a class=\"anchor\" href=\"#http10\">#</a> HTTP/1.0</h4>\n<ol>\n<li>短连接</li>\n<li>HTTP1.0 中，存在⼀些浪费带宽的现象，例如客户端只是需要某个对象的⼀部分，⽽服务器却将整个对象送过来了</li>\n</ol>\n<h4 id=\"http11\"><a class=\"anchor\" href=\"#http11\">#</a> HTTP/1.1</h4>\n<ol>\n<li>HTTP 1.1 起，默认使⽤⻓连接，默认开启 Connection： keep-alive。</li>\n<li>支持 管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。</li>\n<li>HTTP1.1 则在请求头引⼊了 range 头域，它允许只请求资源的某个部分</li>\n<li>Host 是 HTTP 1.1 协议中新增的一个请求头，主要用来实现虚拟主机技术。</li>\n</ol>\n<p>补充：<br />\n虚拟主机（virtual hosting）即共享主机（shared web hosting），可以利用虚拟技术把一台完整的服务器分成若干个主机，因此可以在单一主机上运行多个网站或服务。</p>\n<p>举个栗子，有一台 ip 地址为 61.135.169.125 的服务器，在这台服务器上部署着谷歌、百度、淘宝的网站。为什么我们访问 <span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbQ==\">https://www.google.com</span> 时，看到的是 Google 的首页而不是百度或者淘宝的首页？原因就是 Host 请求头决定着访问哪个虚拟主机。</p>\n<p>缺点：</p>\n<ol>\n<li>请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 Body 的部分；<br />\n发送冗长的首部。每次互相发送相同的首部造成的浪费较多；</li>\n<li>服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞；</li>\n<li>没有请求优先级控制；</li>\n<li>请求只能从客户端开始，服务器只能被动响应。</li>\n</ol>\n<h4 id=\"http2\"><a class=\"anchor\" href=\"#http2\">#</a> HTTP/2</h4>\n<ol>\n<li>头部压缩<br />\n HTTP/2 会压缩头（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你消除重复的分。</li>\n<li>二进制格式<br />\n HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了二进制格式。<br />\n头信息和数据体都是二进制，并且统称为帧（frame）：头信息帧和数据帧。</li>\n<li>数据流<br />\n HTTP/2 的数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。<br />\n每个请求或回应的所有数据包，称为一个数据流（Stream）。<br />\n每个数据流都标记着一个独一无二的编号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数<br />\n客户端还可以指定数据流的优先级。优先级高的请求，服务器就先响应该请求。</li>\n<li>多路复用<br />\n HTTP/2 是可以在一个连接中并发多个请求或回应，而不用按照顺序一一对应。<br />\n移除了 HTTP/1.1 中的串行请求，不需要排队等待，也就不会再出现「队头阻塞」问题，降低了延迟，大幅度提高了连接的利用率。<br />\n<img data-src=\"https://img-blog.csdnimg.cn/374f4758ba9f4527921b023e6b3b75b5.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBALSDlnIjlnIjnmoTnp5HnoJTml6XorrA=,size_12,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\" /></li>\n<li>服务器推送<br />\n HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务不再是被动地响应，也可以主动向客户端发送消息。<br />\n<img data-src=\"https://img-blog.csdnimg.cn/769fa050443d4d67a8121da69534f988.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBALSDlnIjlnIjnmoTnp5HnoJTml6XorrA=,size_13,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\" /></li>\n</ol>\n<h4 id=\"http3\"><a class=\"anchor\" href=\"#http3\">#</a> HTTP/3</h4>\n<p>HTTP/2 主要的问题在于：多个 HTTP 请求在复用一个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。</p>\n<p>所以一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来。</p>\n<p>这都是基于 TCP 传输层的问题，所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！<br />\n<img data-src=\"https://img-blog.csdnimg.cn/98fd3ea62e094983a18cfa97f0f0ba65.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBALSDlnIjlnIjnmoTnp5HnoJTml6XorrA=,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\" /><br />\n大家都知道 UDP 是不可靠传输的，但基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输。</p>\n<h2 id=\"请你谈谈cookie\"><a class=\"anchor\" href=\"#请你谈谈cookie\">#</a> 请你谈谈 Cookie</h2>\n<p>cookie 虽然在持久保存客户端数据提供了方便，分担了服务器存储的负担，但还是有很多局限性的。</p>\n<p>第一：每个特定的域名下最多生成 20 个 cookie</p>\n<p>1.IE6 或更低版本最多 20 个 cookie</p>\n<p>2.IE7 和之后的版本最后可以有 50 个 cookie。</p>\n<p>3.Firefox 最多 50 个 cookie</p>\n<p>4.chrome 和 Safari 没有做硬性限制</p>\n<p>IE 和 Opera 会清理近期最少使用的 cookie，Firefox 会随机清理 cookie。</p>\n<p>cookie 的最大大约为 4096 字节，为了兼容性，一般不能超过 4095 字节。</p>\n<p>IE 提供了一种存储可以持久化用户数据，叫做 userData，从 IE5.0 就开始支持。每个数据最多 128K，每个域名下最多 1M。这个持久化数据放在缓存中，如果缓存没有清理，那么会一直存在。</p>\n<p>优点：极高的扩展性和可用性</p>\n<p>1. 通过良好的编程，控制保存在 cookie 中的 session 对象的大小。</p>\n<p>2. 通过加密和安全传输技术（SSL），减少 cookie 被破解的可能性。</p>\n<p>3. 只在 cookie 中存放不敏感数据，即使被盗也不会有重大损失。</p>\n<p>4. 控制 cookie 的生命期，使之不会永远有效。偷盗者很可能拿到一个过期的 cookie。</p>\n<p>缺点：</p>\n<p>1. <code>Cookie</code>  数量和长度的限制。每个 domain 最多只能有 20 条 cookie，每个 cookie 长度不能超过 4KB，否则会被截掉。</p>\n<p>2. 安全性问题。如果 cookie 被人拦截了，那人就可以取得所有的 session 信息。即使加密也与事无补，因为拦截者并不需要知道 cookie 的意义，他只要原样转发 cookie 就可以达到目的了。</p>\n<p>3. 有些状态不可能保存在客户端。例如，为了防止重复提交表单，我们需要在服务器端保存一个计数器。如果我们把这个计数器保存在客户端，那么它起不到任何作用。</p>\n<h1 id=\"操作系统\"><a class=\"anchor\" href=\"#操作系统\">#</a> 操作系统</h1>\n<h1 id=\"数据库\"><a class=\"anchor\" href=\"#数据库\">#</a> 数据库</h1>\n",
            "tags": [
                "面试"
            ]
        }
    ]
}