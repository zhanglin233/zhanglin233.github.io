---
title: 爬取p站(pixiv)的图片（一）
tags: Python 爬虫
categories:
- [计算机科学,Python,爬虫]
---

pixiv([地址1](https://www.pixiv.net/)，翻不了墙的可以通过[地址2](https://pixivic.com/)访问)上面有很多非常好看的图片,我也经常在上面寻找一些好看的图片，但自己一个一个下载又太慢了，然后刚好自己学的爬虫忘的差不多了，所以就想写个爬虫自动爬取pixiv上的图片，顺带复习一下以前学的知识。  

### 一些图片(这谁扛得住呀，太好看了)  

![]({{site.url}}/images/3.jpg)
![]({{site.url}}/images/2.jpg)
![]({{site.url}}/images/4.jpg)  


### 第一次尝试失败  

因为我的梯子是白嫖的，直接从原网站下载的话可能速度会过慢，所以我选择从国内地址上下载。  
打开网站先输入自己喜欢的类型，我找的是樱花类型。打开了网页之后便开始分析网页结构，为后面的编写代码做准备。打开开发者工具(F12)后便可以看到整个网页的html代码，
![]({{site.url}}/images/11-17-pixiv.png)使用工具栏中的小箭头随便点击一张图片便可在结构中定位到该图片的位置，
![]({{site.url}}/images/11-17-pixiv2.png)我们仔细观察之后就可以发现所有的图片都是位于class='cell-container'的div盒子中，而图片则是位于这个div标签下的img标签中，而每张图片的链接都储存在img标签的，所以理论上接下来我们只需找到每一个img标签并取得所有图片的链接就可以批量下载图片。但是这个网页跟一般的网页不同，一般的的网页可以根据改变页数而选择不同的图片，而这个网页采取的是动态刷新的方式来刷新图片，随着滚动条的滚动图片不断发生改变，而整个网页并不会刷新，网址并不会改变，这就给给我们的工作带来了一定的麻烦。  
这个时候为了能够正常的获取我们所需要的数目的照片，我们就需要继续分析网页。在开发者工具中找到“网络”（'networks'）,我们可以观察到随着我们往下滑动页面，网络中的数据也是不断改变的。本来我是打算先找到post请求，然后就可以找到真正的请求网址，结果他竟然没有post请求！！！networks中直接给出了返回的照片信息，但是我不知道如何收集开发者工具中的img信息，所以只能换个方法。  
随着我们不断地滑动，networks中的内容不断改变，通过观察可以观察到每滑动几下，刷新的数据中除了jpg信息，还有2个'https://pix.ipv4.host/illustrations?illustType=illust&searchType=original&maxSanityLevel=4&page=5&keyword=%E6%A1%9C%E3%81%AE%E8%8A%B1&pageSize=30' 信息，一个是get请求，一个是options请求(虽然我不知道这个请求有什么用)。
![]({{site.url}}/images/20-11-17_pixiv3.png)我们选中其中一个可以发现一个请求url,我通过代码爬取了一下这个网址的源代码(直接点击这个网址是无用的,我是通过在代码添加请求头访问)，发现其中包含了很多的照片的网址，然后再观察一下这个网址的组成，可以大胆猜测我们只要改变网址中'page'的属性值就可以访问到不同的图片组，然后我用代码爬了一下不同的page值的网页发现返回值确实不同，就在我以为我要成功的时候，现实又严重的打击了我的自信心。我试着用代码访问获得的众多的图片网址中的一个时，返回了失败的信息，估计是爬虫做的伪装的还不够，还是被认出来了。但是我暂时并不知道如何改进，所以这种方式我就暂时放弃了。  
接下来继续观察网页返回的信息，可以发现在参数栏中也包含了page信息
![]({{site.url}}/images/20-11-17_pixiv4.png),所以我就打算将这些信息打包成data信息并作为参数传入请求中
~~~
import requests
from lxml import etree

# 网址
url = 'https://pixivic.com/keywords?tag=樱花&illustType=illust&VNK=3fa7b1f4'

# 反爬
header = {
    'accept':
    'application/json, text/plain, */*',
    'accept-encoding':
    'gzip, deflate, br',
    'accept-language':
    'zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6',
    'authorization':
    'eyJhbGciOiJIUzUxMiJ9.eyJwZXJtaXNzaW9uTGV2ZWwiOjIsInJlZnJlc2hDb3VudCI6MSwiaXNCYW4iOjEsInVzZXJJZCI6NTk3NTIyLCJpYXQiOjE2MDU1MzA4ODEsImV4cCI6MTYwNTcwMzY4MX0.yPa-vDYWgMtp6Mer_Ycgyf4r6i6ZQoHFZJGi1v9CjYH7Q7T9Kz_Coa5PwbtZC0j-AvhRFEWaa5D5jxD8WujxBA',
    'dnt':
    '1',
    'origin':
    'https://pixivic.com',
    'referer':
    'https://pixivic.com/',
    'sec-fetch-dest':
    'empty',
    'sec-fetch-mode':
    'cors',
    'sec-fetch-site':
    'cross-site',
    'cookie':
    '__cfduid=d9b53ec0583ae0dc116fee426d77c30891605603315; expires=Thu, 17-Dec-20 08:55:15 GMT; path=/; domain=.cheerfun.dev; HttpOnly; SameSite=Lax',
    'user-agent':
    'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Mobile Safari/537.36 Edg/86.0.622.69'
}
# 提交的数据
dat = {
    'illustType': 'illust',
    'searchType': 'original',
    'maxSanityLevel': '4',
    'page': '2',
    'keyword': '樱花',
    'pageSize': '30',
}

r = requests.get(url, data= dat,headers=header, timeout=30)
print(r.status_code)
r.raise_for_status()  # 如果状态不是200，则引发HTTPERROE异常
text = r.content.decode(encoding='utf-8', errors='ignore')
print(text)
html = etree.HTML(text)
~~~
运行完整代码后，我们可以看到成功返回了信息，
![]({{site.url}}/images/20-11-17_pixiv5.png),但是这些都是没用的，一个有用的东西都没有！！！明显这是又被认出来是爬虫了，这次人家还客气点没有直接拒绝请求访问，只是给了假的页面而已。


所以在折腾了将近一天的时间后还是没有成功的爬取下来图片，只能再去看一些相关的网课来学学怎么更好的伪装骗过系统，太难受了:broken_heart:。
