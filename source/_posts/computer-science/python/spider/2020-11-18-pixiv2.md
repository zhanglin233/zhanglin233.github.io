---
title: 爬取p站(pixiv)的图片（二）
tags: Python 爬虫
categories:
- [计算机科学,Python,爬虫]
---
### 成功爬取pixiv上的图片
在经过了三天的奋战之后，我终于成功的爬取到了pixiv上的图片，看着文件夹里的众多好看的图片的感觉真不错，以后再也不缺壁纸和头像了（hiahiahia）。接下来言归正传，分享一下我是如何爬取到这些图片的。  

### 爬取pixiv上的图片的具体步骤
#### 获取不同照片的id
我在我的[爬取pixiv的第一篇博客](http://zhanglin.space/2020/11/jekyll/)中描述了我的初次尝试的爬取思路，虽然思路并没有问题，但是最终因为网站反扒的原因，我并没有成功的将图片爬取下来，本来我是打算等我再看点如何反“反爬”的教程之后再动手，但是昨天晚上回去的时候我随机点了几张图片观察它们的详细信息时，才发现他的域名是通过改变图片的id值来链接不同的照片,大体都是相同的(我还是太年轻了,经验不够),如https://pixivic.com/illusts/64952228?VNK=f1808200,其中的'64952228'就是图片的id值,当我们将它换成其他照片的id值就可以访问其他的照片，而我昨天通过访问'https://pix.ipv4.host/illustrations?illustType=illust&searchType=original&maxSanityLevel=4&page=5&keyword=%E6%A1%9C%E3%81%AE%E8%8A%B1&pageSize=30' 信息得到了一大串网址，虽然我们不能通过这些网址直接访问到相应的图片，但是我们可以发现这些网址之中也包含了相应的图片的id信息，所以如果我们能够将其中的id信息提取出来，并套到上面的那个网址中，这样我们就能通过代码批量的访问这些图片的地址并进而进行后面的操作。  (如图所示，只要输入类似图中的网址，我们就可以访问到不同的图片)
![]({{site.url}}/images/20-11-18_pixiv5.png)

我们将得到的一大串不能直接访问的网址保存到本地，得到如图所示的结果
![]({{site.url}}/images/20-11-18_pixiv1.png)要提取·其中的id信息最好用的当然是用正则表达式了。
![]({{site.url}}/images/20-11-18_pixiv2.png)(其中i为当前访问的是第几页的内容，后面讲)，这样我们就的到了所有图片的id信息，这个时候我们只需要将id信息填写到基本url中就可以组成能够直接访问到图片的链接。
![]({{site.url}}/images/20-11-18_pixiv3.png)(其中idtag为id+页数，所以提取的时候只需要取前8位就行(id观察后能发现都是8位))，这个时候就完成了我们的第一步。

#### 尝试访问图片链接
正常来说我们获得了可以通过点击便访问到的链接，接下来就是通过代码访问这些链接、获取他们的html信息、并提取到其中能够直接下载的图片的链接，  

![]({{site.url}}/images/20-11-18_pixiv6.png)

你是不是也是这么想的呢,如果是的话，恭喜你也错了(hhh),我们运行一下这部分代码，便会发现它报错了，然后我用selenium模仿搜索了一下，便发现无论输入的是什么网址，打开的都是这个网站的首页，所以我们为了访问到图片的地址，应该伪装成我们是登陆状态，但是我在xhr翻啊翻，只找到了一个'set-cookie'信息，并没有找到cookie信息，而且当我将set-cookie信息加入到headers之中后，还是无法访问到图片(就离谱)，这个时候我实在是没办法了，只能先用selenium登录进这个网站之后再进行后续的操作，操作流程为找到登录按钮的标签->点击登录按钮->填写账号、密码和验证码，之后在访问图片的链接。接下来的事情就更离谱了(我是真不知道一个非赢利的图片网站为什么在反爬上下这么大功夫)，我们用selenium打开pixiv首页，

![]({{site.url}}/images/20-11-18_pixiv11.png)

直接打开的界面为：  
![]({{site.url}}/images/20-11-19_pixiv5.png)

如果这时我们直接用代码寻找登录按钮时找不到的。
我们必须手动叉掉广告和二维码后，代码才能找到登录按钮,而且几秒钟之内不点掉的话，你就叉不掉了(????,我是懵逼了)。  
找到之后，我们就将开始输入的账号和密码自动填入，至于验证码自动识别，我还不是很熟，暂且偷下懒，反正输验证码也不要多久。
![]({{site.url}}/images/20-11-18_pixiv7.png)



#### 下载图片

成功登陆之后，那事情就简单了，获取网页的html信息并提取出图片可下载的地址：

![]({{site.url}}/images/20-11-18_pixiv9.png)

保存图片到本地：

![]({{site.url}}/images/20-11-18_pixiv10.png)

接下来打开文件夹就可以找到照片了

---

### 20-11-19的补充（代码的部分细节改进）
#### 页数的选取

![]({{site.url}}/images/20-11-19_pixiv3.png)
可以选取下载的初始与终止页，不用每次从第一页下载，但是这种我感觉还是不太好，我是打算在本地再建立一个新文件，自动记录下载过的主题、页数和id，以后再弄。

#### id的提取与挑选

原来选取出来的id值既包括了作品的id值，还包括了部分作者的id，这次改进之后只剩下了作品的id。但是这样还是存在另一个问题：

![]({{site.url}}/images/20-11-19_pixiv1.png)

我们可以考到这样提取出来的有些是重复的，如果我们每一个id的图片都要检查一下是否已经存在了就会浪费很多时间，所以我就又改进了一下，在组成网址前去掉重复值，最终代码为：

![]({{site.url}}/images/20-11-19_pixiv4.png)

#### 关键字判断
当输入的关键字找不到相关图片时，提醒用户换个关键字查找并中断程序

![]({{site.url}}/images/20-11-19_pixiv2.png)

### 完结撒花
花了四天的时间终于将这个爬虫程序及博客写好了  ([代码地址](https://github.com/zhanglin233/code/blob/master/.vscode/python/%E7%88%AC%E5%8F%96pixiv%E5%9B%BE%E7%89%87/%E7%88%AC%E5%8F%96%E5%9B%BE%E7%89%87.py))
，真是痛并快乐着，这几天既学到了一些新知识，又复习了一些快忘掉的知识，收获还是很大滴，不枉我这几天没日没夜的改代码、敲博客弄得人都不好了，坐太久了现在脖子都稍微有点痛，这一两天就先休息一下想想下个任务写什么。
